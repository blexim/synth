
\documentclass[preprint]{sigplanconf}

% The following \documentclass options may be useful:

% preprint      Remove this option only once the paper is in final form.
% 10pt          To set in 10-point type instead of 9-point.
% 11pt          To set in 11-point type instead of 9-point.
% authoryear    To obtain author/year citation style instead of numeric.

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{pifont}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{xspace}
\usepackage{pgf}
\usepackage[noend]{algpseudocode}
\usepackage{algorithm}
\usepackage{multicol}
\usepackage{appendix}
\usepackage{caption,subcaption}
\DeclareCaptionType{copyrightbox}
\usepackage{subfig}
\usepackage{multirow}
\usepackage{framed}
\usepackage{tikz}
\usetikzlibrary{arrows, automata, shapes}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{conjecture}[theorem]{Conjecture}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}

\newcommand{\xmark}{\ding{55}}
\newcommand{\todo}[1]{{\bf TODO:} #1}

\lstset{language=c++}



\begin{document}

%\special{papersize=8.5in,11in}
\setlength{\pdfpageheight}{\paperheight}
\setlength{\pdfpagewidth}{\paperwidth}

\conferenceinfo{POPL '14}{Month d--d, 20yy, City, ST, Country} 
\copyrightyear{2014} 

% Uncomment one of the following two, if you are not going for the 
% traditional copyright transfer agreement.

%\exclusivelicense                % ACM gets exclusive license to publish, 
                                  % you retain copyright

%\permissiontopublish             % ACM gets nonexclusive license to publish
                                  % (paid open-access papers, 
                                  % short abstracts)

\title{Synthesising Complex Termination Arguments}

\authorinfo{Cristina David\and Daniel Kroening\and Matt Lewis}
           {Oxford University}
           {firstname.lastname@cs.ox.ac.uk}

\maketitle

\begin{abstract}
Proving program termination is typically done by finding a well-founded \emph{ranking function}
for the program states.
Existing termination provers typically find ranking functions
using either linear algebra or templates.  As such they are often restricted to
finding linear ranking functions over mathematical integers.  This class
of ranking functions is not large enough to prove termination for all terminating
programs, and furthermore a termination argument for a program operating on mathematical integers
does not always lead to a termination argument for the same program operating on
fixed-width machine integers.

We present a reduction from program \emph{termination} to program \emph{synthesis}.
This reduction allows us to generate nonlinear, lexicographic ranking functions that
are correct for fixed-width machine arithmetic and floating-point arithmetic.
We use this reduction to build a sound and complete procedure for the termination
of fixed-width and floating-point arithmetic programs.
\end{abstract}

%\category{CR-number}{subcategory}{third-level}


\keywords
Termination, Program Synthesis, Lexicographic Ranking Functions, Bitvector Ranking Functions,
Floating Point Ranking Functions.

\section{Introduction}\label{sec:intro}

Proving program termination is typically done by finding a \emph{ranking function}
for the program states, i.e. a map from the program's state space to a well-ordered set.
%% As this definition of a ranking function is very general, research is often limited to some
%% convenient and tractable form of ranking functions, most frequently \emph{linear ranking functions} (see Section~\ref{sec:ranking.functions}). 
%% In doing so, an analysis ensures that such a ranking function will be found if one  exists, 
%% while failing to prove termination for terminating programs whose ranking functions fall short of the considered restriction. 

When surveying the area of program termination chronologically, we observe an initial domination of  monolithic approaches based on a single measure shown to decrease
over all program paths %(syntactic characterisation of loops) 
\cite{DBLP:conf/vmcai/P04,DBLP:conf/cav/BradleyMS05}, followed by 
more recent techniques moving towards termination arguments based on Ramsey's theorem \cite{DBLP:conf/lpe/CodishG03,DBLP:conf/lics/PodelskiR04,DBLP:conf/pldi/CookPR06}.
The latter approach aims to find a set of local termination conditions that decrease as execution follows through the loop. %(semantic characterisation of loops).
The main justification for this paradigm shift lies in the simplicity of the local termination measures when compared to the global ones, e.g.
there are cases in which proofs based on local measures involve applying linear functions while corresponding global
measures involve nonlinear functions or lexicographic orders. Consequently, approaches based on Ramsey's theorem 
search for linear termination arguments.


The downside of a Ramsey-based approach is the fact that a valid termination argument must hold for the \emph{transitive closure}
of the program's transitions, rather than only for individual transitions. 
As such, there is experimental evidence that most of the time is spent in reachability analysis \cite{DBLP:conf/pldi/CookPR06}, 
requiring the support of powerful safety checkers.
Basically, these approaches opt for simpler termination arguments in the detriment of complex validity checking.


As Ramsey-based approaches are limited by the state of the art in safety checking, 
recent research shifts back to more complex termination arguments that are easier to check \cite{DBLP:conf/tacas/CookSZ13,DBLP:conf/cav/KroeningSTW10}.
%In \cite{DBLP:conf/tacas/CookSZ13}, Cook et al present an iterative termination proving procedure that searches for 
%lexicographic termination arguments, whereas Kroening et al. strengthen the termination argument such that it becomes a transitive relation \cite{DBLP:conf/cav/KroeningSTW10}.
%
%
Following the same trend, %of switching the complexity in termination checking back to the termination arguments, 
we investigate its extreme: \emph{unrestricted} termination arguments. 
This means that our ranking functions may involve non-linearity and lexicographic orders (we do not commit to any such form, i.e. we do not use templates).


While the summary  in Figure~\ref{fig:handletable} supports our observation that the majority of existing termination analyses are designed for
linear programs and linear ranking functions, it also identifies another common assumption that is being made: the equivalence of bit-vector/float semantics and integer/real semantics. Thus, most of the techniques treat
bit-vectors and floats as mathematical integers and reals, respectively  \cite{DBLP:conf/pldi/CookPR06,DBLP:conf/popl/Ben-AmramG13,DBLP:conf/vmcai/P04,DBLP:conf/atva/HeizmannHLP13,DBLP:conf/vmcai/BradleyMS05,DBLP:conf/cav/KroeningSTW10}. 


By assuming bit-vector/float semantics to be equivalent to integer/real semantics, 
these techniques ignore the wrap-around behaviour caused by under/over-flows as well as width conversions, 
and ultimately diverge from the execution of a program on a computer.  
In Section~\ref{sec:motivation}, we show that integers/reals and bit-vectors/floats exhibit
incomparable behaviours with respect to termination, e.g.
programs that terminate for integers may \emph{not} terminate for bit-vectors.
Thus, abstracting bit-vectors/floats to integers/reals may give rise to 
{\em unsound} and {\em incomplete} analyses.
%design decisions
%which is rather surprising given that bit-vectors and floats are ubiquitous in computer systems. 



%% \noindent {\bf Bit-vectors (machine-level integers) vs. mathematical integers.}
%% The abstraction of bit-vectors to mathematical integers ignores
%% the wrap-around behaviour caused by under/over-flows in bit-vector arithmetic, resulting in
%% incomparable behaviours with respect to termination.

%% Programs that terminate for integers may \emph{not} terminate for bit-vectors. For illustration, consider the following loop:
%% \begin{lstlisting}[language=C]
%% while (x > 0) x -= 2;
%% \end{lstlisting}
%% The loop always terminates for unbounded integers as the value of \texttt{x} does eventually become negative, 
%% whereas, with bit-vector arithmetic, \texttt{x} underflows before becoming negative and goes back to being positive causing the loop to never terminate.

%% Similarly, programs that terminate for bit-vectors may \emph{not} terminate for integers. One such situation is illustrated next:  
%%  \begin{lstlisting}[language=C]
%%  while(x > 0) x++;
%%  \end{lstlisting}
%% This loop is  terminating for bit-vectors since \texttt{x}
%% will eventually over-flow and become negative. Conversely, the same program is non-terminating using integer
%% arithmetic since the loop condition stays always true for any initial \texttt{x} at least 1.

%% %Similarly, programs that terminate for bit-vectors may \emph{not} terminate for integers. One such situation is illustrated next:  

%% \begin{lstlisting}[language=C]
%% while (x > 0) x -= 2;
%% \end{lstlisting}

%% \begin{lstlisting}[language=C]
%%  while(x > 0) x++;
%%  \end{lstlisting}

%% %\noindent {\bf Floats vs. reals.} 
%% A scenario similar to the one for bit-vectors happens if floats were to be abstracted to unbounded reals by termination provers \cite{}. 
%% Consequently, these provers ignore potential rounding errors, under- and over-flows, which are precisely what makes  reasoning about floating point inherently difficult.
%% This approximation may lead to erroneous diagnosis of a program's terminating behaviour as illustrated by the loops in Figure~\ref{} and Figure~\ref{}.
%% While the former does not terminate for reals, but does for floats, the latter 
%% terminates for reals, but does not for floats.

%% \begin{lstlisting}
%% while (x > 0.0) x *= 0.5;
%% \end{lstlisting}

%% \begin{lstlisting}
%% while (x > 0.0) x -= 1.0;
%% \end{lstlisting}
%% \todo{explain the reasons for non-termination with figures.}\\


%% \noindent {\bf Linear programs and linear ranking functions.} As visible in Figure~\ref{fig:handletable}, 
%% most termination techniques assume \emph{restrictive transition relations}, e.g. linear programs,  and are only able to compute
%% \emph{linear ranking functions} \cite{}. To better understand this restriction, we computed the probability of a random terminating program having a linear ranking
%% function (see Section ?). This probability proved to be very low, indicating that the linearity assumption for the ranking functions is indeed prohibitive.


We propose a general framework that does not assume the existence of linear ranking functions and can uniformly compute
\emph{lexicographic/non-lexicographic} \emph{linear/non-linear} 
ranking functions supported by inductive \emph{linear/non-linear} invariants for loops with 
\emph{linear/non-linear} guards and transitions over bit-vectors and floats.
Our technique is {\emph complete} and can handle programs with non-linear operations, e.g. logical and.
In our design, the termination problem becomes as hard as finding ranking functions, rather than as hard as
checking the validity of a termination argument. 

 
Given the level of generality that we aim for, we phrase the termination problem as a second order satisfaction problem (indeed, a program synthesis problem) (Section~\ref{}).
While investigating the search space and the distribution of solutions (Section~\ref{}), we identify factors influencing our method's performance and
find that our technique %is semantic in nature and 
does not dependent on the size of the analysed program or its number of variables, but on the Kolmogorov
 complexity of the computed ranking functions. We show that the probability of
a ranking function to have a low Kolmogorov complexity is higher than the probability to be linear (see Section~?).
Moreover, we find that our technique does actually gain from the generality of the termination argument. 
After investigating its theoretical bounds, we experimentally show that our technique performs well in practice. 


\begin{figure*}
\centering
 \begin{tabular}{|ll||c|c|c|c|c|c|c|c|}
 \hline
  & & \multicolumn{8}{c|}{Program} \\
  & & \multicolumn{2}{c|}{Integers} & \multicolumn{2}{c|}{Reals} & \multicolumn{2}{c|}{Bit-vectors} & \multicolumn{2}{c|}{Floats} \\
  & & L & NL & L & NL & L & NL & L & NL \\
  \hline
  \hline
  \multirow{4}{*}{Ranking} & Linear lexicographic &  \cite{DBLP:conf/cav/BradleyMS05,DBLP:conf/tacas/CookSZ13,DBLP:conf/vmcai/P04} && & &\checkmark&\checkmark&\checkmark&\checkmark\\
   & Linear non-lexicographic & \cite{DBLP:conf/pldi/CookPR06,DBLP:conf/cav/LeeWY12,DBLP:conf/popl/Ben-AmramG13,DBLP:conf/vmcai/P04,DBLP:conf/atva/HeizmannHLP13,DBLP:conf/vmcai/BradleyMS05,DBLP:conf/cav/KroeningSTW10} & \cite{DBLP:conf/vmcai/BradleyMS05} & && \checkmark~ \cite{DBLP:conf/tacas/CookKRW10} &\checkmark~ \cite{DBLP:conf/tacas/CookKRW10}&\checkmark&\checkmark\\
   & Non-linear lexicographic &  &  & &&\checkmark&\checkmark&\checkmark&\checkmark\\
   & Non-linear non-lexicographic & \cite{DBLP:conf/vmcai/BradleyMS05} &  \cite{DBLP:conf/vmcai/BradleyMS05} & &&\checkmark&\checkmark&\checkmark&\checkmark\\
   \hline
 \end{tabular}

 \caption{Legend: \checkmark = we can handle\label{fig:handletable}}
\end{figure*}


%We empirically observe that most programs have
%ranking functions with low Kolmogorov complexity (see Section ?). 

%Church was BIG into program synthesis~\cite{church-synth}, so you know it's good stuff.
%Something, something, Curry-Howard Isomorphism, something, something, programs-as-proofs.

 The main contributions of our work can be summarised as follows:
\begin{itemize}
\item We designed a technique for computing ranking functions that correctly accounts for the wrap-around behavior caused by under- and overflows in bit-vector and floating point arithmetic. To the best of our knowledge, this is the first approach able to compute ranking functions for programs handling floats. Our technique is not restricted to finding linear ranking functions, but can also compute (lexicographic) non-linear  ones. We justified the need for such a non restrictive procedure by computing the probability ... .
\item  We rephrased the termination problem as a second-order satisfaction problem and made 
use of results in genetic programming to efficiently solve it. We have also investigated the effects of genetic operators on the search space for ranking functions and computed theoretical 
bounds on the convergence time ...
\item We present a formulation that allows us to prove termination without an expensive reachability check (as we don't use Ramsey-based termination arguments).  In particular,
we only need a bounded model checker that performs a single unwinding of a loop.
%% \item Our technique is able to uniformly handle conditionally-terminating loops, as well as programs with
%% multiple loops.
\item We implemented our technique and tried it on a selection of programs handling both bit-vectors and floats.
\end{itemize}

%. only non-strict inequalities can be transformed using Farkas’ Lemma
%--Our approach to termination analysis has two distinct features over previous works
%-- a lexicographic ranking function imposes a lexicographic ordering on among the ranking function components.

% The main advantage of our approach is its unitary nature. We do not require any initial assumption regarding the form of the termination  
% argument, as this does not influence our search process. We identify the factors influencing the performance of our design and 
% show that these factors are independent on the linearity of the ranking function or the number of lexicographic components...


%semantic approach

%given that the search space size is constant, the probability of finding a solution 
%increases when considering all the possible solutions. There is no point in restricting the form of the solution..
%to read: constraint-based.., integers vs rationals.

%This paper is organised as follows:

\section{Related Work}
%\subsection{Termination analysis}
Automated program termination is a research topic that has received a fair amount of attention from the software verification community.
In order to compare our technique to the rest of the area, 
Figure~\ref{fig:handletable} summarises the related works with respect to the restrictions they impose on the transition relations as well as the form of the computed ranking functions. 


Somehow expected, most of the techniques are specialised in the synthesis of linear ranking functions for linear programs over integers (or rationals) \cite{DBLP:conf/pldi/CookPR06,DBLP:conf/cav/LeeWY12,DBLP:conf/popl/Ben-AmramG13,DBLP:conf/vmcai/P04,DBLP:conf/atva/HeizmannHLP13,DBLP:conf/cav/BradleyMS05,DBLP:conf/tacas/CookSZ13}. 
Among them, 
Lee et al. make use of transition predicate abstraction, algorithmic learning, and decision procedures to compute transition
invariants as proofs for the termination of linear programs \cite{DBLP:conf/cav/LeeWY12}.
Leike and Heizmann present a new method for the constraint-based synthesis
of termination arguments for linear loop programs based on
linear ranking templates \cite{DBLP:conf/tacas/LeikeH14}.
Linear ranking functions supported by inductive linear invariants for loops with linear guards and transitions: \cite{DBLP:conf/cav/BradleyMS05}. 
Learning: \cite{DBLP:journals/corr/HeizmannHP14}


%A program is lasso-shaped if it is composed by a stem followed by a single loop without branching, i.e. there is only one path. 
%Consequently, the termination argument can be very simple. There are numerous techniques specialised in
%proving termination of lasso-shaped programs efficiently \cite{DBLP:conf/popl/Ben-AmramG13,DBLP:conf/cav/BradleyMS05,DBLP:conf/atva/HeizmannHLP13,DBLP:conf/vmcai/P04}. 

While the synthesis of termination arguments for linear programs over integers is indeed well-covered in the literature, 
there is very limited work for programs over machine integers.
Cook et al. present a method based on a reduction to Presburger
arithmetic, and a template-matching approach for predefined classes of
ranking functions based on reduction to SAT- and QBF-solving \cite{DBLP:conf/tacas/CookKRW10}.
Similarly, the only work we are aware of that can compute non-linear ranking functions  
for imperative loops with polynomial guards and polynomial assignments
is \cite{DBLP:conf/vmcai/BradleyMS05}. However, this work extends only to polynomials.

Given the lack of research in handling \emph{not-linear programs}, as well as \emph{programs over bit-vectors and floats},  
our work focuses on covering these areas. 
One of the obvious conclusions that can be reached from observing Figure~\ref{fig:handletable}, 
is that most of the works tend to specialise on a certain aspect of termination proving that they can solve efficiently. 
Conversely to this view, we aim for \emph{generality}, as we do not restrict the form of the synthesised ranking functions, nor the form of the input programs.


As mentioned in Section~\ref{sec:intro}, approaches based on Ramsey's theorem compute a set of local termination conditions that decrease as execution follows through the loop
and require expensive reachability analyses
\cite{DBLP:conf/lpe/CodishG03,DBLP:conf/lics/PodelskiR04,DBLP:conf/pldi/CookPR06}.
In an attempt to reduce the complexity of checking the validity of the termination argument, 
Cook et al present an iterative termination proving procedure that searches for 
lexicographic termination arguments \cite{DBLP:conf/tacas/CookSZ13}, 
whereas Kroening et al. strengthen the termination argument such that it becomes a transitive relation \cite{DBLP:conf/cav/KroeningSTW10}.

\todo{add smth about synthesis}

%The existing work on termination is primarily divided into structural (syntactic) vs. semantic approaches.  
%For example, terminationg of term rewriting systems is largely structural, whereas DWF analysis (cf. Terminator) is more semantic. While it deals
%with transition relations, it also uses some amount of syntax in that it identifies loops \& looping paths.



%-- Usually the termination argument for the program LOOPS
%on Figure 1 is based on a lexicographic combination
%of well-founded orderings.


%\subsection{Synthesis}

\section{Motivational Examples} \label{sec:motivation}
In the previous sections, we have discussed some of the assumptions made by existent termination analyses (see Figure~\ref{fig:handletable}). 
Now, we provide some simple examples that broke those assumptions and 

We next discus some intricate examples that prove challenging for existent termination analysis.
%a few examples that illustrate the difficulties in termination checking for low-level code. In particular, they denote situations that arise 
%frequently in practise and are not properly handled by existing techniques. 

%We now present a few examples that justify 

\subsection{Program linearity vs. the linearity of its ranking function.}
The first examples we consider illustrate the lack of a direct correlation between the linearity of a program and that of its termination arguments.
As such, Figure~\ref{} denotes a program with non-linear operations. Given that  many of the existing techniques commit to linear programs, they cannot handle this situation, 
although a linear ranking function does exist (see Figure~\ref{fig:handletable}). 

In order to find a ranking function for this example, it is necessary to take into account
the semantics of the bit-wise AND operator, which is not easily done when working with mathematical integers \cite{}.
Our technique finds that a possible ranking function is the linear function
$R(x) = x$, whose value decreases with
every iteration, but it can not decrease indefinitely as it is bounded from below.

Conversely, Figure~\ref{} shows a linear program with a non-linear ranking function.

Figure~\ref{} is a linear program taken from \cite{DBLP:conf/tacas/CookSZ13}, where it is shown to not admit (without prior manipulation) a lexicographic linear function, but only a disjunctively well-founded one, 
which requires an expensive binary reachability analysis.
However, by using our technique we can find a non-linear lexicographic ranking functions.
A lexicographic non-linear ranking functions consists of lexicographically ordered components
of non-linear functions. As with linear lexicographic ranking functions, a state is mapped to a tuple of values such that the
loop transition leads to a decrease with respect to the lexicographic
ordering for this tuple. Therefore no function may increase unless a function of
a lower index decreases. Additionally, at every step, there must be at least one
function that decreases.

\begin{figure*}
\centering
 \begin{tabular}{ccc}

\begin{subfigure}[b]{0.3\textwidth}
\begin{lstlisting}
while (x > 0)
 x = (x - 1) & x;
\end{lstlisting}
\caption{}
 \label{fig:motivation.a}
\end{subfigure}%

&

\begin{subfigure}[b]{0.3\textwidth}
\begin{lstlisting}
while (x != 0)
 x = -x / 2;
\end{lstlisting}
\caption{}
 \label{fig:motivation.b}
\end{subfigure}%

&

\begin{subfigure}[b]{0.3\textwidth}
\begin{lstlisting}[language=C]
 while(x > 0) x++;
 \end{lstlisting}
\caption{}
 \label{fig:motivation.c}
\end{subfigure} \\

\hline

\begin{subfigure}[b]{0.3\textwidth}
\begin{lstlisting}
  while ( q >= 0 ) {
    q = q - y;
    y = y + 1;
  }
\end{lstlisting}
\caption{}
 \label{fig:motivation.d}
\end{subfigure} 

&

\begin{subfigure}[b]{0.3\textwidth}
\begin{lstlisting}
while (x > 0.0) x -= 1.0;
\end{lstlisting}
\caption{}
 \label{fig:motivation.f}
\end{subfigure} 

&

\begin{subfigure}[b]{0.3\textwidth}
\begin{lstlisting}
while (x > 0.0) x *= 0.5;
\end{lstlisting}
\caption{}
 \label{fig:motivation.g}
\end{subfigure} \\
\hline

\begin{subfigure}[b]{0.3\textwidth}
\begin{lstlisting}
  while (x != 0) {
    if (x > 0)
      x--;
    else
      x++;
  }
\end{lstlisting}
\caption{}
 \label{fig:motivation.h}
\end{subfigure} 


&

\begin{subfigure}[b]{0.3\textwidth}
\begin{lstlisting}
while (x > 0 && y > 0 && z > 0) {
    if (y > x) {
      y = z;
      x = nondet();
      z = x - 1;
    } else {
      z = z - 1;
      x = nondet();
      y = x - 1;
    }
}
\end{lstlisting}
\caption{}
 \label{fig:motivation.h}
\end{subfigure} 

&

\end{tabular}
\caption{Sample programs}\label{fig:motivation}
\end{figure*}

\subsection{Differences in the termination behaviour for integers and bit-vectors.}
We have collected a number of motivational examples from other termination papers that treat bit-vectors as mathematical integers \cite{DBLP:conf/tacas/LeikeH14,DBLP:conf/tacas/CookSZ13}. 
We show that the termination arguments computed by such techniques do not directly apply when considering the bit-vector semantics.
%these programs actually exhibit different terminating behaviours for bit-vectors and integer  

\begin{lstlisting}
  while (x != m) {
    if (x > m)
      x = 0;
    else
      x++;
  }
\end{lstlisting}

The program in Figure~\ref{} is taken from \cite{DBLP:conf/tacas/CookSZ13}, where
$m$ and $x$ start as any integers with $m$ positive. If $x$ is greater than
$m$, $x$ is set to 0. Otherwise, $x$ increases until it equals $m$, upon which
the loop terminates. While a disjunctive well-founded termination argument does exist for the loop, 
e.g. ($x < oldx$ and $0 \leq oldx$) or ($m-x < oldm-oldx$ and $0 \leq oldm-oldx$), the loop does not 
terminate under the bit-vector semantics. The reason is ..

\begin{lstlisting}
  while ( q >= 0 ) {
    q = q - y;
    y = y + 1;
  }
\end{lstlisting}

In Figure~\ref{}, every execution of the program can be partitioned into two phases: in the first phase $y$ increases
until it is positive (in this phase $q$ may increase), whereas in the second $q$ decreases until the loop condition is violated. 
This example was presented in \cite{DBLP:conf/tacas/LeikeH14}, where the authors make use of a template for obtaining a ranking function that proceeds
through a fixed number of phases in the program execution. Each phase is ranked by a linear function, and ends when this function becomes non-positive.
However, when considering the bit-vector semantics, this program does not terminate as..

\subsection{Differences in the termination behaviour for reals and floats.}
\begin{lstlisting}
while (x > 0.0) x -= 1.0;
\end{lstlisting}

\begin{lstlisting}
while (x > 0.0) x *= 0.5;
\end{lstlisting}


\subsection{Multi-phase ranking functions}
%\subsection{Lexicographic ranking function with strict inequalities.}
%Approaches based on Farkas’ Lemma can only handle non-strict inequalities \cite{DBLP:conf/cav/BradleyMS05,DBLP:conf/vmcai/P04}.
The program in Figure~\ref{} is taken from SVCOMP'15  \footnote{http://sv-comp.sosy-lab.org/2015/index.php} termination benchmarks.
In the terminology of \cite{DBLP:conf/tacas/LeikeH14}, this program admits a multi-phase ranking function, i.e. ..,  with a dedicated technique for computing it. However, in our setting 
this type of programs do not need a special treatment, as we can find a non-linear ranking function for it as follows:
\begin{verbatim}
R(x, y, z) = (x < y, z)
\end{verbatim}


\begin{lstlisting}
int main(void) {
  int x, y, z;

  while (x > 0 && y > 0 && z > 0) {
    if (y > x) {
      y = z;
      x = nondet();
      z = x - 1;
    } else {
      z = z - 1;
      x = nondet();
      y = x - 1;
    }
  }
}
\end{lstlisting}



\section{Preliminaries}
\subsection{Termination and Ranking Functions} \label{sec:ranking.functions}
\todo{linear program}

A transition system with state space $X$ and transition relation $T \subseteq X \times X$
is said to be \emph{unconditionally terminating} if there is no infinite sequence
$x_1, x_2, \ldots$ with $\forall i . T(x_i, x_{i+1})$.  We can prove that $T$ is
unconditionally terminating by finding an injective function $R: X \to Y$ where
$Y$ is well-founded and $R$ is monotonically decreasing with respect $T$.  That is
to say:
$$\forall x, x' . T(x, x') \Rightarrow R(x) < R(x')$$

A special case of a ranking function is a \emph{linear ranking function}.  This
class of functions is exactly what you'd expect: a linear function that satisfies
the criteria for a ranking function.  We recall that a linear function $f: X \to Y$,
with $\dim(X) = n$ and $\dim(Y) = m$
is one that can be expressed as an $n \times m$ matrix $M$:
$$f(\vec{x}) = M\vec{x}$$

In the case that $\dim(Y) = 1$, this reduces to an inner product:
$$f(\vec{x}) = \vec{\lambda} \cdotp \vec{x} + c$$

If $Y = Z^m$, we say that the ranking function is \emph{lexicographic},
and require that the total order imposed on $Y$ is the lexicographic ordering
induced on tuples of $Z$'s.  We note that some termination arguments
require lexicographic ranking functions, or equivalently, ranking functions
whose co-domain is the ordinals, rather than just $\mathbb{N}$.

\subsection{Disjunctive Well-Foundedness}\label{sec:dwf}
Terminator uses disjunctive well foundedness arguments, which can be found
piece by piece, but require reasoning about the transitive closure of a transition
relation.  Because we build a monolithic well foundedness argument, we
do not need to reason about the full transitive closure, and can instead do our
reasoning over a single step of the transition relation.  This means that we
can get away with very simple model checking methods, rather than requiring
a full-blown safety prover.

\subsection{Machine Arithmetic and Bitvectors} \label{sec:machine.arith} 
Physical computers have bounded storage, which means they are unable to perform calculations on mathematical
integers.  For example, if $A$ is the Ackermann function and $G$ is Graham's number, a physical computer
capable of computing $A(G, G)$ would contain (much!) more matter than is believed to exist in the universe.
Fortunately, it is rare for a programmer to need such a large number and so modern computers do their arithmetic
over fixed-width binary words, otherwise known as bit-vectors.  For the remainder of this section, we will say that
the bit-vectors we are working with are $k$-bits wide, which means that each word can hold one of $2^k$ bit patterns.
Typical values for $k$ are 32 and 64.

Bit-vector arithmetic is performed modulo $2^k$, which is the source of many of the differences between
machine arithmetic and Peano arithmetic.  To give an example: $(2^k - 1) + 1 \equiv 0 \pmod {2^k}$.
This provides a counterexample to the statement $\forall x . x + 1 > x$, which is a theorem of Peano
arithmetic but not of modular arithmetic.  When an arithmetic operation has a result greater than $2^k$,
it is said to ``overflow''.  If an operation does not overflow, its machine-arithmetic result is the same
as the result of the same operation performed on integers.

Machine words can be interpreted as ``signed'' or ``unsigned'' values.  Signed values can be negative,
while unsigned values cannot.  The encoding for signed values is two's complement, where the most significant
bit $b_{k-1}$ of the word is a ``sign'' bit, whose weight is $-(2^k - 1)$ rather than $2^k - 1$.  Two's complement
representation has the property that $\forall x . -x = (\mathord{\sim} x) + 1$, where $\mathord{\sim}(\bullet)$
is bitwise-negation.  Two's complement also has the property that addition, multiplication and subtraction are defined
identically for unsigned and signed numbers.  Therefore signed and unsigned arithmetic differ only on comparison
operators\footnote{There is also the difference that signed overflow in a C program results in undefined behaviour,
but in practice the undefined behaviour is implemented just as if the arithmetic had been unsigned}.
For example: $$\forall x . -x \leq_s x \wedge -x \geq_u x$$ where $\leq_s$ and $\geq_u$ represent signed and unsigned comparisons respectively.

The final source of difference between integer arithmetic and bitvector arithmetic stems from width conversions.
Typical computers allow variables to have different types, which can be represented using words of different widths.
In C a \texttt{short} might occupy
16 bits, while an \texttt{int} might occupy 32 bits.  If a $k$-bit variable is assigned to a $l$-bit variable
with $l < k$, the result is truncated $\mod 2^l$.  For example, if $x$ is a 32-bit variable and $y$ is a 16-bit
variable, $y$ will hold the value $0$ after the following code is executed:

\begin{lstlisting}
x = 65536;
y = x;
\end{lstlisting}

This gives us a counterexample to the statement $\forall x, y . x = y \Rightarrow (x + 1) = (y + 1)$,
which is a theorem of Peano arithmetic.

As well as machine arithmetic differing from Peano arithmetic on the operators they have in common,
computers have several ``bitwise'' operations that are not taken as primitive in the theory of
integers.  These operations include the standard boolean operations \texttt{and, or, not, xor}
applied to each element of the bit-vector.  Computer programs often make use of these operators,
which are non-linear when interpreted in the standard model of Peano arithmetic
(although some of these operators can be seen as linear in a different algebraic structure,
e.g. \texttt{xor} corresponds to addition in the Galois field $\mathrm{GF}(2^k)$).

\iffalse
\section{Combinatorics of Finite Termination}
In this section, we fix a model of computation, describe its semantics and
define the syntax of a language we will work over.

\subsection{Syntax and Semantics}

\begin{itemize}
 \item Our transition relation is $T(x, x') \subseteq X \times X$.
 \item Our loop condition is $L(x) \subseteq X$.
 \item Our ranking function is $R(x) : X \to Y$.
 \item Our state space has size $\| X \| = M = 2^k$.
 \item Our ranking co-domain has size $\| Y \| = N = 2^j$.
 \item The number of looping states is $\| L \| = l$.
 \item Our transition relation is deterministic and parititioned into chains of length $c_i$, with $l = \sum c_i$.
\end{itemize}

\subsection{Counting Programs}
\begin{itemize}
 \item There are a TON of programs (way more than you'd expect).
 \item There are a TON of terminating programs, and for our model of computation we can count
  how many (the Chaitin constant).
 \item There are a TON of ranking functions (way more than you'd expect, but not many as a
  fraction of programs).
 \item There are not many linear functions.
 \item Most terminating programs don't admit linear ranking functions.
 \item The Curry-Howard isomorphism
 \item Kolmogorov complexity is relevant for understanding termination proofs.
\end{itemize}


\begin{theorem}
 A random function $f : X \to Y$ is a ranking function for $(T, L)$ with probability

 $$N^{-l} \times \prod {{N-1} \choose c_i}$$
\end{theorem}

\begin{proof}
 Combinatorics.
\end{proof}


\begin{corollary}
 This number is really small (e.g. $10^{-193}$ for a 64-bit program with 1 variable and 10 looping states.
 Randomly sampling functions \& hoping they're ranking functions is not going to work.
\end{corollary}


\begin{conjecture}
 The probability that a random program $(T, L)$ is terminating (the Chaitin constant)
 is $0.7$.
\end{conjecture}

\begin{conjecture}
 The probability that a random program $(T, L)$ admits a linear ranking function is
 $0.1$.
\end{conjecture}

\begin{conjecture}
 The probability that a random, terminating program $(T, L)$ admits a linear ranking function
 is $0.2$.
\end{conjecture}


\begin{corollary}
 Most terminating programs do not have linear ranking functions.
\end{corollary}
\fi


\section{Termination as Second-Order Satisfaction}
In this section we will show how several variations of the halting problem can be defined in second-order
logic.  As it turns out, all of these variations can be defined in a fragment of second-order logic
we will refer to as the \emph{synthesis fragment}.  We will make use of this observation to frame the halting
problem as a program synthesis problem, allowing us to employ the program synthesiser described in
Section~\ref{sec:synthesis}.

\begin{figure*}
\begin{framed}
\begin{definition}[Second-order Termination Formula]
\label{def:termination-formula}
\begin{align*}
 \exists R \cdot \forall x, x' \cdot & L(x) \wedge T(x, x') \rightarrow R(x) > 0 \wedge R(x) > R(x')
\end{align*}
\end{definition}

\begin{definition}[Conditional Termination Formula]
\label{def:conditional-termination-formula}
 \begin{align*}
  \exists R, V \cdot \forall x, x' \cdot & I(x) \rightarrow V(x) ~ \wedge \\
                                 & L(x) \wedge V(x) \wedge T(x, x') \rightarrow V(x') \wedge R(x) > 0 \wedge R(x) > R(x')
 \end{align*}
\end{definition}

\begin{definition}[Multiple Loops Termination Formula]
\label{def:multi-termination-formula}
 \begin{align*}
  \exists R, V_1, V_2 \cdot \forall x, x' \cdot & I(x) \rightarrow V_1(x) ~ \wedge \\
                                        & V_1(x) \wedge L_1(x) \wedge T(x, x') \rightarrow V_1(x') ~ \wedge \\
                                        & V_1(x) \wedge \lnot L_1(x) \rightarrow V_2(x) ~ \wedge \\
                                        & V_2(x) \wedge L_2(x) \wedge T(x, x') \rightarrow V_2(x') \wedge R(x) > 0 \wedge R(x) > R(x')
 \end{align*}
\end{definition}

\begin{definition}[Non-Termination Formula]
\label{def:nonterm-formula}
 \begin{align*}
  \exists N, x_0 \cdot \forall x \cdot \exists x' \cdot & I(x_0) \wedge L(x_0) \wedge N(x_0) ~ \wedge \\
							& N(x) \wedge L(x) \rightarrow T(x, x') \wedge N(x') \wedge L(x')
 \end{align*}
\end{definition}

\begin{definition}[Deterministic Non-Termination Formula]
\label{def:deterministic-nonterm-formula}
 \begin{align*}
  \exists N, x_0 \cdot \forall x, x' \cdot & I(x_0) \wedge L(x_0) \wedge N(x_0) ~ \wedge \\
							& N(x) \wedge L(x) \wedge T(x, x') \rightarrow N(x') \wedge L(x')
 \end{align*} 
\end{definition}
\end{framed}
\end{figure*}



\iffalse
Many loops do not terminate for all starting states, but are contained in programs that guarantee the loop will
terminate.  Traditional termination provers have difficulty reasoning about such conditionally-terminating loops.
We are able to handle such loops by computing \emph{termination invariants}.  This mechanism also allows us to
prove that programs with multiple loops terminate, even if the termination of some loop depends on the states
reachable after leaving a previous loop.

Our method for ranking function synthesis can be stated as follows:
discuss what spec is used (non-lexicographic vs lexicographic) + the completeness claims.
Any termination guarantees?  
\fi


The existence of a ranking function for a single loop is equivalent to the satisfiability
of the formula from Definition~\ref{def:termination-formula}.  If this formula is satisfiable,
$R$ is a ranking function that proves the loop $L$ terminates.

A slightly more involved case occurs if $L$'s termination depends on the state it begins
executing in, i.e. $L$ is \emph{conditionally terminating}.  This property is equivalent to the
formula of Defintion~\ref{def:conditional-termination-formula}.  If this formula is satisfiable,
$V$ is an inductive invariant of $L$ that is established by the initial states $I$.
$R$ is then a ranking function for $L$ as restricted by $V$ -- that is to say, $R$ need only
be well founded on those states satisfying $V$.  But since $V$ is an inductive invariant of $L$,
$R$ is strong enough to show that $L$ terminates from any of its initial states.  We say
that $V$ is a \emph{termination invariant} for $L$ and that $R$ proves termination relative to $V$.

The conditional termination formula becomes more complex in the presence of multiple loops.
Consider the following program with two loops $L_1$ and $L_2$, one after the other:

\begin{lstlisting}
while (L1) { ... }
while (L2) { ... }
\end{lstlisting}

The termination problem for $L_2$ is equivalent to the satisfiability of
Definition~\ref{def:multi-termination-formula}.  If this formula is satisfiable,
$V_1$ is an inductive invariant of $L_1$ and $V_2$ is a termination invariant of $L_2$.
$V_1$ is established by the initial conditions $I$ and is strong enough to establish
$V_2$ when conjoined with the negation of $L_1$'s guard.  As before, $R$ is a ranking
function relative to $V_2$.

Non-termination of the loop $L$ is encoded by Definition~\ref{def:nonterm-formula}.
If this formula is satisfiable, $N$ is a recurrence set for $L$ which proves
$L$'s non-termination.  However this formula has one more level of quantifier alternation
than the others (it is an $\exists \forall \exists$ formula), which will cause us problems
shortly.  We observe that in the case that $T$ is deterministic (that is, each state has
exactly one successor),  the non-termination problem is equivalent to the
satisfiability of Definition~\ref{def:deterministic-nonterm-formula}.

With the exception of Definition~\ref{def:nonterm-formula}, each of the second-order formulae
above is an $\exists \forall$ formula where the the universally quantified variables only range over
ground terms.  We refer to this syntactic class as the \emph{synthesis fragment} of second-order
logic, because program synthesis problem can be described as finding a satisfying assigment to the
following formula:

\begin{definition}[Synthesis Formula]
 \label{def:synth-formula}
 $$\exists P, x \cdot \forall y \cdot \sigma(x, y, P)$$
\end{definition}

Here we can view $\sigma: X \times Y \times (X \times Y \to Z) \to \mathbb{B}$ as a specification function.
The idea is that $\sigma$ returns true iff the function $P$ computes appropriate outputs
when fed the inputs $x$ and $y$.  If we can find a function $P$ and a value $x$ that meet the specification
for all $y$, we have found a solution to the synthesis problem and write $P \models \sigma$.  Since the formulae
of Fig.~\ref{fig:termination-formulae} are syntactically in the synthesis fragment, by concocting an appropriate
specification function we reduce the problem of proving termination to the problem of
program synthesis.

\subsection{Synthesis Complexity}
In Section~\ref{sec:synthesis} we will describe a procedure for solving the synthesis formula.
This procedure has the property that it will find the shortest program meeting the
specification, and as a consequence the runtime of the program synthesiser is dominated
by the size of this shortest program.  To frame the discussion of the runtime of our
termination proving procedure, we first recall the definition of the Kolmogorov complexity
of a function $f$:

\begin{definition}[Kolmogorov complexity]
 The Kolmogorov complexity $K(f)$ is the length of the shortest program that
 computes $f$.
\end{definition}

We can extend this definition slightly to talk about the Kolmogorov complexity of a
synthesis problem in terms of its specification:

\begin{definition}[Kolmogorov complexity of a synthesis problem]
 The Kolmogorov complexity of a program specification $K(\sigma)$ is the length of the shortest
 program $P$ such that $P \models \sigma$.
\end{definition}

We will later show that the time complexity of our synthesis procedure is $NP^{NP}(K(\sigma))$,
which means that for even moderately large $K(\sigma)$ our procedure is intractably slow.  Conversely
if $K(\sigma)$ is small we will be able to find a termination proof, regardless of other parameters
such as the size of the program under analysis.  To put this another way, under the assumption
that $K(\sigma)$ is small for a program's termination problem, we will find a ranking function
quite rapidly.  We will now investigate the properties of functions with low Kolmogorov complexity,
and show that the assumption of a low-Kolmogorov ranking function is much weaker than the assumption
of a linear ranking function.


\begin{theorem}
 Linear functions have low Kolmogorov complexity.
\end{theorem}

\begin{proof}
 The function $f: X \to Y$ can be computed with a program consisting of
 $2 \cdot \dim(X) \cdot \dim(Y) - \dim(Y)$ instructions (1 multiplication and 1 addition for
 each cell in the matrix representing $f$).  Therefore,
 $K(f) \leq 2 \cdot \dim(X) \cdot \dim(Y) - \dim(Y)$.
\end{proof}

\begin{theorem}
Assuming a reasonable program encoding, the probability that a random program of length $l$ computes
a linear function is $O(2^{-l})$.
\end{theorem}

(Discussion of linearity vs. LKC here)

\iffalse
\begin{corollary}
 LKC is a weaker assumption than linearity.
\end{corollary}


\begin{theorem}
 LKC programs do not always have LKC ranking functions.
\end{theorem}

\begin{proof}
 This would solve the halting problem, Goldbach conjecture, Collatz conjecture.
\end{proof}

\begin{conjecture}
 High-Kolmogorov-complexity (HKC) programs often have LKC ranking functions.
\end{conjecture}

\begin{theorem}
 \textsc{Headshot} is biased towards finding ranking functions with
 low-Kolmogorov-complexity (LKC).
\end{theorem}

\begin{proof}
 Trivial.
\end{proof}

\subsection{The linearity assumption vs. the LKC one for ranking functions}

\begin{conjecture}
 Most LKC programs compute non-linear functions, but linear functions are LKC.
 So LKC is a weaker assumption than linearity.
\end{conjecture}

\begin{corollary}
 \textsc{Headshot} can often prove termination where linear methods cannot.
\end{corollary}
\fi

\section{Solving the Synthesis Formula}
We can solve the synthesis problem using any off-the-shelf program synthesiser.  If you don't
have a program synthesiser kicking around, we present the design of one synthesiser
that can be used to solve the problem.

\iffalse
\subsection{The Search Space and the Kolmogorov Complexity of a Ranking Function}
\begin{conjecture}
The lexicographic ordering does not influence the size of the search space. Thus, finding potentially lexicographic termination arguments is not more difficult than finding non-lexicographic ones.   
\end{conjecture}

As a consequence of the aforementioned conjecture, we do not need to commit to a specific form of the termination argument. While other approaches, e.g. \cite{DBLP:conf/tacas/LeikeH14}, 
conduct independent searches for each possible form of the ranking function with some of them futile whenever the assumed constrained ranking function does not exist, we have a single search that aims at finding the ranking function with the lowest Kolmogorov complexity. 
\fi


\input{kalashnikov}

\section{Genetic Programming and Incremental Evolution}

We begin by observing that the asymptotic complexity of all of our synthesis
backends are equal, assuming $P \neq NP$.  This complexity is:

$$O(2^{K(f)}$$

Where $K(f)$ is the Kolmogorov complexity of $f$, which is $O(\log Y^X) = O(X)$
so the complexity is doubly exponential in the width of $X$.

\begin{definition}
 A \emph{fitness landscape} is the space of all programs along with their fitness.
\end{definition}

\begin{theorem}
 Fitness landscapes form a lattice.  Adding test vectors corresponds to abstraction refinement on this
 lattice, which is why incremental GP works well.
\end{theorem}

\begin{proof}
 Trivial.
\end{proof}


\begin{conjecture}
 A single fitness landscape isn't really very smooth (e.g. small changes in program representation
 don't correspond to small changes in fitness), so GP probably shouldn't work very well.
 
 But it does.
\end{conjecture}



\section{Experiments}

We proved termination for a bunch of programs, see Fig.~\ref{fig:linear} and Fig.~\ref{fig:nonlinear}.

\begin{figure*}
\centering
\begin{tabular}{|l|r|r||r|r|r|r|}
\hline
    & LOC & \shortstack{Rank function \\ size} & \textsc{T2} & \textsc{ARMC} & \textsc{Headshot} & \textsc{Headshot-Linear} \\
    \hline
    \hline
 P1 & 10 & 3 & 100s & 70s & 0.1s & \bf{0.01s} \\
 P2 & 10 & 3 & 100s & 70s & 0.1s & \bf{0.01s} \\
 P3 & 10 & 3 & 100s & 70s & 0.1s & \bf{0.01s} \\
 \hline
\end{tabular}
\caption{Termination for linear programs with disjunctive, linear ranking functions\label{fig:linear}}
\end{figure*}

\begin{figure*}
\centering
\begin{tabular}{|l|r|c|c|c|c|r|r|r|}
\hline
    & LOC & \shortstack{Linear \\ program?} & \shortstack{Linear ranking \\ function?}  & Conditional? & Float? & Dimension & \shortstack{Ranking \\ program size} & Time (s)\\
    \hline
    \hline
 P1 & 10 & \xmark & \xmark & \xmark & \xmark & 3 & 1 & 0.01 \\
 P2 & 10 & \xmark & \xmark & \xmark & \xmark & 3 & 1 & 0.01 \\
 P3 & 10 & \xmark & \xmark & \xmark & \xmark & 3 & 1 & 0.01 \\
 \hline
\end{tabular}

\caption{\textsc{Headshot} termination for nonlinear programs with nonlinear ranking functions\label{fig:nonlinear}}
 \end{figure*}


\bibliographystyle{abbrvnat}
\bibliography{synth}{}

\end{document}
