
\documentclass[preprint]{sigplanconf}

% The following \documentclass options may be useful:

% preprint      Remove this option only once the paper is in final form.
% 10pt          To set in 10-point type instead of 9-point.
% 11pt          To set in 11-point type instead of 9-point.
% authoryear    To obtain author/year citation style instead of numeric.

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{pifont}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{xspace}
\usepackage{pgf}
\usepackage[noend]{algpseudocode}
\usepackage{algorithm}
\usepackage{multicol}
\usepackage{appendix}
\usepackage{caption,subcaption}
\DeclareCaptionType{copyrightbox}
\usepackage{subfig}
\usepackage{multirow}
\usepackage{framed}
\usepackage{tikz}
\usetikzlibrary{arrows, automata, shapes}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{conjecture}[theorem]{Conjecture}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}

\newcommand{\xmark}{\ding{55}}
\newcommand{\todo}[1]{{\bf TODO:} #1}
\newcommand{\newC}{C$^-$\xspace}

\lstset{language=c++}



\begin{document}

%\special{papersize=8.5in,11in}
\setlength{\pdfpageheight}{\paperheight}
\setlength{\pdfpagewidth}{\paperwidth}

\conferenceinfo{POPL '14}{Month d--d, 20yy, City, ST, Country} 
\copyrightyear{2014} 

% Uncomment one of the following two, if you are not going for the 
% traditional copyright transfer agreement.

%\exclusivelicense                % ACM gets exclusive license to publish, 
                                  % you retain copyright

%\permissiontopublish             % ACM gets nonexclusive license to publish
                                  % (paid open-access papers, 
                                  % short abstracts)

\title{Deciding Bitvector Termination with Program Synthesis}

\authorinfo{Cristina David\and Daniel Kroening\and Matt Lewis}
           {Oxford University}
           {firstname.lastname@cs.ox.ac.uk}

\maketitle

\begin{abstract}
Proving program termination is typically done by finding a well-founded \emph{ranking function}
for the program states.
Existing termination provers typically find ranking functions
using either linear algebra or templates.  As such they are often restricted to
finding linear ranking functions over mathematical integers.  This class
of ranking functions is not large enough to prove termination for all terminating
programs, and furthermore a termination argument for a program operating on mathematical integers
does not always lead to a termination argument for the same program operating on
fixed-width machine integers.

We present a reduction from program \emph{termination} to program \emph{synthesis}.
This reduction allows us to generate nonlinear, lexicographic ranking functions that
are correct for fixed-width machine arithmetic and floating-point arithmetic.
We use this reduction to build a sound and complete procedure for the termination
of fixed-width and floating-point arithmetic programs.
\end{abstract}

%\category{CR-number}{subcategory}{third-level}


\keywords
Termination, Program Synthesis, Lexicographic Ranking Functions, Bitvector Ranking Functions,
Floating Point Ranking Functions.

\section{Introduction}\label{sec:intro}


The halting problem has been of central interest to computer scientists since it was first
considered by Turing in 1936~\cite{turing}.  Informally, we can say that the halting problem
is concerned with answering the question ``does this
program run forever, or will it eventually terminate?''

Proving program termination is typically done by finding a \emph{ranking function}
for the program states, i.e. a monotone map from the program's state space to a well-ordered set.
Historically, the search for ranking functions has been constrained in various syntactic ways, leading to
incompleteness, and
is performed over abstractions that do not soundly capture the behaviour of physical computers.
In this paper, we present a sound and complete method for deciding whether a program terminates.

%% As this definition of a ranking function is very general, research is often limited to some
%% convenient and tractable form of ranking functions, most frequently \emph{linear ranking functions} (see Section~\ref{sec:ranking.functions}). 
%% In doing so, an analysis ensures that such a ranking function will be found if one  exists, 
%% while failing to prove termination for terminating programs whose ranking functions fall short of the considered restriction. 

When surveying the area of program termination chronologically, we observe an initial domination of  monolithic approaches based on a single measure shown to decrease
over all program paths %(syntactic characterisation of loops) 
\cite{DBLP:conf/vmcai/P04,DBLP:conf/cav/BradleyMS05}, followed by 
more recent techniques moving towards termination arguments based on Ramsey's theorem \cite{DBLP:conf/lpe/CodishG03,DBLP:conf/lics/PodelskiR04,DBLP:conf/pldi/CookPR06}.
The latter approach aims to find a set of local termination conditions that decrease as execution follows through the loop. %(semantic characterisation of loops).
The main justification for this paradigm shift lies in the simplicity of the local termination measures when compared to the global ones, e.g.
there are cases in which proofs based on local measures involve applying linear functions while corresponding global
measures involve nonlinear functions or lexicographic orders. 
This explains why approaches based on Ramsey's theorem are restricted to searching for linear termination arguments.


The downside of a Ramsey-based approach is the fact that a valid termination argument must hold for the \emph{transitive closure}
of the program's transitions, rather than only for individual transitions. 
As such, there is experimental evidence that most of the time is spent in reachability analysis \cite{DBLP:conf/pldi/CookPR06}, 
requiring the support of powerful safety checkers.
Basically, these approaches opt for simpler termination arguments in the detriment of complex validity checking.


As Ramsey-based approaches are limited by the state of the art in safety checking, 
recent research shifts back to more complex termination arguments that are easier to check \cite{DBLP:conf/tacas/CookSZ13,DBLP:conf/cav/KroeningSTW10}.
%In \cite{DBLP:conf/tacas/CookSZ13}, Cook et al present an iterative termination proving procedure that searches for 
%lexicographic termination arguments, whereas Kroening et al. strengthen the termination argument such that it becomes a transitive relation \cite{DBLP:conf/cav/KroeningSTW10}.
%
%
Following the same trend, %of switching the complexity in termination checking back to the termination arguments, 
we investigate its extreme: \emph{unrestricted} termination arguments. 
This means that our ranking functions may involve non-linearity and lexicographic orders (we do not commit to any such form, i.e. we do not use templates).


While the summary  in Figure~\ref{fig:handletable} supports the observation that the majority of existing termination analyses are designed for
linear programs and linear ranking functions, it also identifies another common assumption made by state of the art termination provers: 
\emph{the equivalence of bit-vector/float semantics and integer/real semantics}. Thus, most of the techniques treat
bit-vectors and floats as mathematical integers and reals, respectively  \cite{DBLP:conf/pldi/CookPR06,DBLP:conf/popl/Ben-AmramG13,DBLP:conf/vmcai/P04,DBLP:conf/atva/HeizmannHLP13,DBLP:conf/vmcai/BradleyMS05,DBLP:conf/cav/KroeningSTW10}. 


By assuming bit-vector/float semantics to be equivalent to integer/real semantics, 
these techniques ignore the wrap-around behaviour caused by under/over-flows as well as width conversions, 
and ultimately diverge from the execution of a program on a computer.  
In Section~\ref{sec:motivation}, we show that integers/reals and bit-vectors/floats exhibit
incomparable behaviours with respect to termination, e.g.
programs that terminate for integers may \emph{not} terminate for bit-vectors.
Thus, abstracting bit-vectors/floats to integers/reals may give rise to 
{\em unsound} and {\em incomplete} analyses.
%design decisions
%which is rather surprising given that bit-vectors and floats are ubiquitous in computer systems. 



%% \noindent {\bf Bit-vectors (machine-level integers) vs. mathematical integers.}
%% The abstraction of bit-vectors to mathematical integers ignores
%% the wrap-around behaviour caused by under/over-flows in bit-vector arithmetic, resulting in
%% incomparable behaviours with respect to termination.

%% Programs that terminate for integers may \emph{not} terminate for bit-vectors. For illustration, consider the following loop:
%% \begin{lstlisting}[language=C]
%% while (x > 0) x -= 2;
%% \end{lstlisting}
%% The loop always terminates for unbounded integers as the value of \texttt{x} does eventually become negative, 
%% whereas, with bit-vector arithmetic, \texttt{x} underflows before becoming negative and goes back to being positive causing the loop to never terminate.

%% Similarly, programs that terminate for bit-vectors may \emph{not} terminate for integers. One such situation is illustrated next:  
%%  \begin{lstlisting}[language=C]
%%  while(x > 0) x++;
%%  \end{lstlisting}
%% This loop is  terminating for bit-vectors since \texttt{x}
%% will eventually over-flow and become negative. Conversely, the same program is non-terminating using integer
%% arithmetic since the loop condition stays always true for any initial \texttt{x} at least 1.

%% %Similarly, programs that terminate for bit-vectors may \emph{not} terminate for integers. One such situation is illustrated next:  

%% \begin{lstlisting}[language=C]
%% while (x > 0) x -= 2;
%% \end{lstlisting}

%% \begin{lstlisting}[language=C]
%%  while(x > 0) x++;
%%  \end{lstlisting}

%% %\noindent {\bf Floats vs. reals.} 
%% A scenario similar to the one for bit-vectors happens if floats were to be abstracted to unbounded reals by termination provers \cite{}. 
%% Consequently, these provers ignore potential rounding errors, under- and over-flows, which are precisely what makes  reasoning about floating point inherently difficult.
%% This approximation may lead to erroneous diagnosis of a program's terminating behaviour as illustrated by the loops in Figure~\ref{} and Figure~\ref{}.
%% While the former does not terminate for reals, but does for floats, the latter 
%% terminates for reals, but does not for floats.

%% \begin{lstlisting}
%% while (x > 0.0) x *= 0.5;
%% \end{lstlisting}

%% \begin{lstlisting}
%% while (x > 0.0) x -= 1.0;
%% \end{lstlisting}
%% \todo{explain the reasons for non-termination with figures.}\\


%% \noindent {\bf Linear programs and linear ranking functions.} As visible in Figure~\ref{fig:handletable}, 
%% most termination techniques assume \emph{restrictive transition relations}, e.g. linear programs,  and are only able to compute
%% \emph{linear ranking functions} \cite{}. To better understand this restriction, we computed the probability of a random terminating program having a linear ranking
%% function (see Section ?). This probability proved to be very low, indicating that the linearity assumption for the ranking functions is indeed prohibitive.


We propose a general framework that %does not assume the existence of linear ranking functions and can 
uniformly computes
\emph{lexicographic/non-lexicographic} \emph{linear/non-linear} 
ranking functions supported by inductive \emph{linear/non-linear} invariants for loops with 
\emph{linear/non-linear} guards and transitions over bit-vectors and floats.
%Our technique is {\emph complete} and can handle programs with non-linear operations, e.g. logical and.
%--In our design, the termination problem becomes as hard as finding ranking functions, rather than as hard as
%checking the validity of a termination argument. 
We combine the generation of ranking functions with the generation of invariants such that the necessary 
supporting invariants and the ranking function are discovered at the same time.

 
For this purpose, we phrase the termination and non-termination problems as second order satisfaction problem and
we identify a fragment of second-order logic that is expressive enough to capture our formulation, 
which we call \emph{the synthesis fragment}. Subsequently, we propose a method 
for checking the satisfiability of a formula in the synthesis fragment as program synthesis (Section~\ref{sec:synthesis}). 
Our method is theoretically complete, i.e. if a pair of a ranking function and a supporting invariant 
exist, it will be found. 

With respect to the performance of our technique, we show that its runtime is dominated by the size of 
the shortest termination proof.
%While investigating the search space and the distribution of solutions (Section~\ref{}), we identify factors 
%influencing our method's performance and
%find that our technique  
This means that our procedure is not directly dependent on the structure of the analysed loop, e.g. number of variable, number of lassos, 
but on the Kolmogorov complexity of its minimal termination argument. 
\emph{In our design, proving a program terminates becomes as hard as finding its minimal temination argument}.
We argue that the length of a program's termination proof is indicative of how easy to understand the program is, and thus 
programmers tend to write programs that have relatively short termination proofs. 
We empirically show that this claim holds in practice, causing our technique to perform well.


%% Our approach to proving termination has two distinct features over previous work. 
%% First, it is \emph{general}, i.e. does not make any assumption about the form of the termination argument.   
%% Second, it correctly handles bit-vectors and floats without abstracting them to integers and reals, respectively.


\begin{figure*}
\centering
 \begin{tabular}{|ll||c|c|c|c|c|c|c|c|}
 \hline
  & & \multicolumn{8}{c|}{Program} \\
  & & \multicolumn{2}{c|}{Integers} & \multicolumn{2}{c|}{Reals} & \multicolumn{2}{c|}{Bit-vectors} & \multicolumn{2}{c|}{Floats} \\
  & & L & NL & L & NL & L & NL & L & NL \\
  \hline
  \hline
  \multirow{4}{*}{Ranking} & Linear lexicographic &  \cite{DBLP:conf/cav/BradleyMS05,DBLP:conf/tacas/CookSZ13,DBLP:conf/vmcai/P04} && & &\checkmark&\checkmark&\checkmark&\checkmark\\
   & Linear non-lexicographic & \cite{DBLP:conf/pldi/CookPR06,DBLP:conf/cav/LeeWY12,DBLP:conf/popl/Ben-AmramG13,DBLP:conf/vmcai/P04,DBLP:conf/atva/HeizmannHLP13,DBLP:conf/vmcai/BradleyMS05,DBLP:conf/cav/KroeningSTW10} & \cite{DBLP:conf/vmcai/BradleyMS05} & && \checkmark~ \cite{DBLP:conf/tacas/CookKRW10} &\checkmark~ \cite{DBLP:conf/tacas/CookKRW10}&\checkmark&\checkmark\\
   & Non-linear lexicographic &  &  & &&\checkmark&\checkmark&\checkmark&\checkmark\\
   & Non-linear non-lexicographic & \cite{DBLP:conf/vmcai/BradleyMS05} &  \cite{DBLP:conf/vmcai/BradleyMS05} & &&\checkmark&\checkmark&\checkmark&\checkmark\\
   \hline
 \end{tabular}

 \caption{Legend: \checkmark = we can handle\label{fig:handletable}}
\end{figure*}


%We empirically observe that most programs have
%ranking functions with low Kolmogorov complexity (see Section ?). 

%Church was BIG into program synthesis~\cite{church-synth}, so you know it's good stuff.
%Something, something, Curry-Howard Isomorphism, something, something, programs-as-proofs.

 The main contributions of our work can be summarised as follows:


\begin{itemize}
\item We designed a bit-level accurate technique for computing ranking functions that correctly accounts for the wrap-around behavior
caused by under- and overflows in bit-vector and floating point arithmetic. Our technique is not restricted to finding linear ranking functions,
but can also compute lexicographic non-linear  ones.

\item  We rephrased the termination and non-termination problems as second-order satisfaction problems and used
program synthesis techniques to solve them. In contrast to previous approaches to program synthesis, we found that
using genetic programming was very effective at generating candidate termination and non-termination proofs.

\item Our procedure does not require the enumeration of lassos, or directly reasoning about the transitive closure of the transition relation.
To verify our proofs, we only require a single call to a SAT solver.

%\item We present a formulation that allows us to prove termination without an expensive reachability check (as we don't use Ramsey-based termination arguments).  In particular,
%we only need a bounded model checker that performs a single unwinding of a loop.

%% \item Our technique is able to uniformly handle conditionally-terminating loops, as well as programs with
%% multiple loops.

\item Our procedure is based on a series of source-to-source transformations.  As well as leading to a concise implementation,
this has the side effect of ensuring that our proof is correct for the exact binary produced by a particular compiler,
rather than for an abstraction of the program.

\item We implemented our technique and tried it on a selection of programs handling both bit-vectors and floats.

\end{itemize}
% unified approach to termination and non-termination
%. only non-strict inequalities can be transformed using Farkas’ Lemma
%--Our approach to termination analysis has two distinct features over previous works
%-- a lexicographic ranking function imposes a lexicographic ordering on among the ranking function components.

% The main advantage of our approach is its unitary nature. We do not require any initial assumption regarding the form of the termination  
% argument, as this does not influence our search process. We identify the factors influencing the performance of our design and 
% show that these factors are independent on the linearity of the ranking function or the number of lexicographic components...


%semantic approach

%given that the search space size is constant, the probability of finding a solution 
%increases when considering all the possible solutions. There is no point in restricting the form of the solution..
%to read: constraint-based.., integers vs rationals.

%This paper is organised as follows:

{\bf Limitations.}
Our algorithm decides termination of transition systems with finite state spaces.
The (non-)termination proofs take the form of ranking functions and program invariants
that are expressed in a quantifier free language.  This formalism is powerful
enough to handle a large fragment of C, but is not rich enough to analyse
code using any of the following features:

\begin{itemize}
\item Recursion (could probably do this).
\item Heap (Thor).
\item Arrays.
\end{itemize}




\section{Motivational Examples} \label{sec:motivation}
Figure~\ref{fig:handletable} illustrates the most common assumptions made by existent termination analyses:
\begin{itemize}
\item[(i)] programs are linear.
\item[(ii)] terminating programs have linear termination arguments.
\item[(iii)] bit-vectors semantics and mathematical integers semantics are equivalent.
\item[(iv)] floats semantics and mathematical reals semantics are equivalent.
\end{itemize}  

%In the previous sections, we have discussed some of the assumptions made by existent termination analyses (see Figure~\ref{fig:handletable}). 
Next, we show how these assumptions are broken by even simple programs that cannot therefore be handled accurately by state of the art termination tools.

%We next discus some intricate examples that prove challenging for existent termination analysis.

%\subsection{Program linearity vs. the linearity of its ranking function.}

%Figure~\ref{fig:handletable} shows that the most common assumption existent termination techniques make is that \emph{programs are linear}.
The loop in Figure~\ref{fig:motivation.a} breaks assumption (i) as it makes use of the bit-wise $\&$ operator.
%As such, Figure~\ref{} denotes a program with non-linear operations. Given that  many of the existing techniques commit to linear programs, they cannot handle this situation, 
%although a linear ranking function does exist (see Figure~\ref{fig:handletable}). 
%In order to find a ranking function for this example, it is necessary to take into account
%the semantics of the bit-wise AND operator.
Our technique finds that a possible ranking function is the linear function
$R(x) = x$, whose value decreases with
every iteration, but cannot decrease indefinitely as it is bounded from below.
This example also illustrates the lack of a direct correlation between the linearity of a program and that of its termination arguments.

Assumption (ii) is broken by the loop in Figure~\ref{fig:motivation.b}.
We prove that this loop terminates by finding that the non-linear function $R(x) = |x|$ is a possible ranking function.

Figure~\ref{fig:motivation.c} invalidates assumption (iii). 
This loop is  terminating for bit-vectors since \texttt{x}
will eventually over-flow and become negative. Conversely, the same program is non-terminating using integer
arithmetic as the loop condition stays always true for any initial \texttt{x} at least 1.

Assumption (iii) is broken again by the program in Figure~\ref{fig:motivation.d}. Every execution of the program can be partitioned into two phases: 
in the first phase $y$ increases until it is positive (in this phase $q$ may increase), whereas in the second $q$ decreases until the loop condition is violated. 
This example is taken from \cite{DBLP:conf/tacas/LeikeH14}, where the authors make use of a template for obtaining a ranking function that proceeds
through a fixed number of phases in the program execution. Each phase is ranked by a linear function, and ends when this function becomes non-positive.
However, when considering the bit-vector semantics, this program does not terminate as..\todo{change this example}

The loops in Figure~\ref{fig:motivation.e} and Figure~\ref{fig:motivation.f} break assumption (iv) as their terminating behaviour is different 
for floats and mathematical reals. 
%This assumption may lead to erroneous diagnosis of a program's terminating behaviour.
The former does not terminate for floats (if $x$ is sufficiently large, the rounding makes the subtraction negligible), but does for reals. Conversely, the latter 
doesn't terminate for reals, but does so for floats (due to rounding errors $x$ eventually becomes sufficiently small 
such that the closest representable number is 0.0). \todo{can we prove non-termination?}


Up until this point, we looked at examples that are not soundly treated by existing techniques as they 
don't fit in the range of programs covered by these techniques.
Next, we look at some programs that are handled by existing termination tools via dedicated analyses. We show that our method 
uniformly handles them, without the need for any special treatment.
% we are able to compute termination arguments in several interesting case

% Our technique gains from generality. A possible explanation for this (perhaps initially sur-
%prising) fact is that, for synthesis, we are interested in the mere existence of a
%% solution, and the loss of
%% many solutions does not necessarily mean the loss of
%% all solutions of the constraint
% bit-level analysis
%These non-terminating programs represent an important class of
%bugs, especially for denial-of-service related vulnerabilities, where
%an attacker can exploit the overflow. Equally important,
% equally important



Figure~\ref{fig:motivation.g} is a linear program taken from \cite{DBLP:conf/tacas/CookSZ13}, 
where it is shown to not admit (without prior manipulation) a lexicographic linear function, but only a Ramsey-based termination argument,
which requires an expensive binary reachability analysis.
With our technique we can find a non-linear lexicographic ranking function $R(x) = |x|$ 
(a lexicographic non-linear ranking functions consists of lexicographically ordered components
of non-linear functions). 
%As with linear lexicographic ranking functions, a state is mapped to a tuple of values such that the
%loop transition leads to a decrease with respect to the lexicographic
%ordering for this tuple. Therefore no function may increase unless a function of
%a lower index decreases. Additionally, at every step, there must be at least one
%function that decreases.


The loop in Figure~\ref{fig:motivation.i} is taken from SVCOMP'15  \footnote{http://sv-comp.sosy-lab.org/2015/index.php} termination benchmarks.
In the terminology of \cite{DBLP:conf/tacas/LeikeH14}, this program admits a multiphase ranking function computed from a multiphase ranking template.
A multiphase ranking template is targeted at programs that go through a
finite number of phases in their execution. Each phase is ranked with
an affine-linear function and the phase is considered to be completed once this
function becomes non-positive.
However, in our setting this type of programs do not need a special treatment, as we can find a non-linear ranking function:
\begin{verbatim}
R(x, y, z) = (x < y, z)
\end{verbatim}

The loop in Figure~\ref{fig:motivation.h} illustrates conditional termination.
When proving program termination we are simultaneously solving two problems:
the search for a termination argument, and the search for a supporting invariant.
We iteratively construct a termination argument as a pair of a ranking function and supporting invariant through a single refinement loop.
For this loop, we find the ranking function $R(x) = x$ together with the supporting invariant $y=1$.

\begin{figure*}
\centering
 \begin{tabular}{ccc}

\begin{subfigure}[b]{0.3\textwidth}
\begin{lstlisting}
while (x > 0)
 x = (x - 1) & x;
\end{lstlisting}
\caption{}
 \label{fig:motivation.a}
\end{subfigure}%

&

\begin{subfigure}[b]{0.3\textwidth}
\begin{lstlisting}
while (x != 0)
 x = -x / 2;
\end{lstlisting}
\caption{}
 \label{fig:motivation.b}
\end{subfigure}%

&

\begin{subfigure}[b]{0.3\textwidth}
\begin{lstlisting}[language=C]
 while(x > 0) x++;
 \end{lstlisting}
\caption{}
 \label{fig:motivation.c}
\end{subfigure} \\

\hline

\begin{subfigure}[b]{0.3\textwidth}
\begin{lstlisting}
  while ( q >= 0 ) {
    q = q - y;
    y = y + 1;
  }
\end{lstlisting}
\caption{}
 \label{fig:motivation.d}
\end{subfigure} 

&

\begin{subfigure}[b]{0.3\textwidth}
\begin{lstlisting}
while (x > 0.0) x -= 1.0;
\end{lstlisting}
\caption{}
 \label{fig:motivation.e}
\end{subfigure} 

&

\begin{subfigure}[b]{0.3\textwidth}
\begin{lstlisting}
while (x > 0.0) x *= 0.5;
\end{lstlisting}
\caption{}
 \label{fig:motivation.f}
\end{subfigure} \\
\hline

\begin{subfigure}[b]{0.3\textwidth}
\begin{lstlisting}
  while (x != 0) {
    if (x > 0)
      x--;
    else
      x++;
  }
\end{lstlisting}
\caption{}
 \label{fig:motivation.g}
\end{subfigure} 


&

\begin{subfigure}[b]{0.3\textwidth}
\begin{lstlisting}
  y = 1;

  while (x > 0) {
    x = x-y;
  }
\end{lstlisting}
\caption{}
 \label{fig:motivation.h}
\end{subfigure} 


&


\begin{subfigure}[b]{0.3\textwidth}
\begin{lstlisting}
while (x > 0 && y > 0 && z > 0) {
    if (y > x) {
      y = z;
      x = nondet();
      z = x - 1;
    } else {
      z = z - 1;
      x = nondet();
      y = x - 1;
    }
}
\end{lstlisting}
\caption{}
 \label{fig:motivation.i}
\end{subfigure} 



\end{tabular}
\caption{Sample programs}\label{fig:motivation}
\end{figure*}

%\subsection{Differences in the termination behaviour for integers and bit-vectors.}
%We have collected a number of motivational examples from other termination papers that treat bit-vectors as mathematical integers \cite{DBLP:conf/tacas/LeikeH14,DBLP:conf/tacas/CookSZ13}. 
%We show that the termination arguments computed by such techniques do not directly apply when considering the bit-vector semantics.
%these programs actually exhibit different terminating behaviours for bit-vectors and integer  

%% \begin{lstlisting}
%%   while (x != m) {
%%     if (x > m)
%%       x = 0;
%%     else
%%       x++;
%%   }
%% \end{lstlisting}

%% The program in Figure~\ref{} is taken from \cite{DBLP:conf/tacas/CookSZ13}, where
%% $m$ and $x$ start as any integers with $m$ positive. If $x$ is greater than
%% $m$, $x$ is set to 0. Otherwise, $x$ increases until it equals $m$, upon which
%% the loop terminates. While a disjunctive well-founded termination argument does exist for the loop, 
%% e.g. ($x < oldx$ and $0 \leq oldx$) or ($m-x < oldm-oldx$ and $0 \leq oldm-oldx$), the loop does not 
%% terminate under the bit-vector semantics. The reason is ..


%\subsection{Multi-phase ranking functions}
%\subsection{Lexicographic ranking function with strict inequalities.}
%Approaches based on Farkas’ Lemma can only handle non-strict inequalities \cite{DBLP:conf/cav/BradleyMS05,DBLP:conf/vmcai/P04}.


\section{Preliminaries}
Given a program, %with state space $X$ and transition relation $T \subseteq X \times X$, 
we first formalise its termination argument as a ranking function (Section~\ref{sec:ranking.functions}). 
Subsequently, we discus bit-vector semantics and illustrate 
differences between machine arithmetic and integer arithmetic that
make the abstraction of bit-vectors to mathematical integers unsound (Section~\ref{sec:machine.arith}).



\subsection{Termination and Ranking Functions} \label{sec:ranking.functions}
A programs $P$ is represented as a transition systems with state space $X$, transition relation $T \subseteq X \times X$, and set of variables $x$. 
A state of the program is a valuation of the variables from $x$. For a state $s \in X$ with $T(s,s')$ we say $s'$
is the successor of $s$ under $T$. 

\begin{definition}[Unconditional termination]
A transition system is said to be \emph{unconditionally terminating} if there is no infinite sequence of states
$x_1, x_2, \ldots \in X$ with $\forall i . T(x_i, x_{i+1})$.  
\end{definition}

We can prove that the transition system is unconditionally terminating by finding a ranking function for its transition relation.

\begin{definition}[Ranking function]
An injective function ${R:X\to Y}$ is a \emph{ranking function} for the transition relation $T$ if $Y$ is a well-founded set and 
$R$ is monotonically decreasing with respect to $T$.  That is
to say:
$$\forall x, x' \in X. T(x, x') \Rightarrow R(x) < R(x')$$
\end{definition}

\begin{definition}[Linear ranking function]
A \emph{linear ranking function} $R: X \to Y$ 
with $\dim(X) = n$ and $\dim(Y) = m$ is of the form: $$f(\vec{x}) = M\vec{x}$$ where
$M$ is an $n \times m$ matrix.
\end{definition}

In the case that $\dim(Y) = 1$, this reduces to an inner product:
$$f(\vec{x}) = \vec{\lambda} \cdotp \vec{x} + c$$

\begin{definition}[Lexicographic ranking function]
For $Y = Z^m$, we say that a ranking function $R: X \to Y$ is \emph{lexicographic}
if it maps each state in $X$ to a tuple of values such that the loop transition leads to a decrease with
respect to the lexicographic ordering for this tuple.
The total order imposed on $Y$ is the lexicographic ordering
induced on tuples of $Z$'s. 
\end{definition}

For lexicographic ranking functions, no function may increase unless a function of a lower index decreases.
Additionally, at every step, there must be at least one function that decreases.
We note that some termination arguments require lexicographic ranking functions, or equivalently, ranking functions
whose co-domain is the ordinals, rather than just $\mathbb{N}$.
%In the rest of the paper, we consider any ranking function $R: X \to Z^m$ to be lexicographic, and the situation when $m=1$ to be a special case.


%% \begin{definition}{Supportive invariant}
%% \end{definition}


\subsection{Machine Arithmetic and Bitvectors} \label{sec:machine.arith} 
Physical computers have bounded storage, which means they are unable to perform calculations on mathematical
integers.  For example, if $A$ is the Ackermann function and $G$ is Graham's number, a physical computer
capable of computing $A(G, G)$ would contain (much!) more matter than is believed to exist in the universe.
Fortunately, it is rare for a programmer to need such a large number and so modern computers do their arithmetic
over fixed-width binary words, otherwise known as bit-vectors.  For the remainder of this section, we will say that
the bit-vectors we are working with are $k$-bits wide, which means that each word can hold one of $2^k$ bit patterns.
Typical values for $k$ are 32 and 64.

Bit-vector arithmetic is performed modulo $2^k$, which is the source of many of the differences between
machine arithmetic and Peano arithmetic.  To give an example: $(2^k - 1) + 1 \equiv 0 \pmod {2^k}$.
This provides a counterexample to the statement $\forall x . x + 1 > x$, which is a theorem of Peano
arithmetic but not of modular arithmetic.  When an arithmetic operation has a result greater than $2^k$,
it is said to ``overflow''.  If an operation does not overflow, its machine-arithmetic result is the same
as the result of the same operation performed on integers.

Machine words can be interpreted as ``signed'' or ``unsigned'' values.  Signed values can be negative,
while unsigned values cannot.  The encoding for signed values is two's complement, where the most significant
bit $b_{k-1}$ of the word is a ``sign'' bit, whose weight is $-(2^k - 1)$ rather than $2^k - 1$.  Two's complement
representation has the property that $\forall x . -x = (\mathord{\sim} x) + 1$, where $\mathord{\sim}(\bullet)$
is bitwise-negation.  Two's complement also has the property that addition, multiplication and subtraction are defined
identically for unsigned and signed numbers.  Therefore signed and unsigned arithmetic differ only on comparison
operators\footnote{There is also the difference that signed overflow in a C program results in undefined behaviour,
but in practice the undefined behaviour is implemented just as if the arithmetic had been unsigned}.
For example: $$\forall x . -x \leq_s x \wedge -x \geq_u x$$ where $\leq_s$ and $\geq_u$ represent signed and unsigned comparisons respectively.

The final source of difference between integer arithmetic and bitvector arithmetic stems from width conversions.
Typical computers allow variables to have different types, which can be represented using words of different widths.
In C a \texttt{short} might occupy
16 bits, while an \texttt{int} might occupy 32 bits.  If a $k$-bit variable is assigned to a $l$-bit variable
with $l < k$, the result is truncated $\mod 2^l$.  For example, if $x$ is a 32-bit variable and $y$ is a 16-bit
variable, $y$ will hold the value $0$ after the following code is executed:

\begin{lstlisting}
x = 65536;
y = x;
\end{lstlisting}

This gives us a counterexample to the statement $\forall x, y . x = y \Rightarrow (x + 1) = (y + 1)$,
which is a theorem of Peano arithmetic.

As well as machine arithmetic differing from Peano arithmetic on the operators they have in common,
computers have several ``bitwise'' operations that are not taken as primitive in the theory of
integers.  These operations include the standard boolean operations \texttt{and, or, not, xor}
applied to each element of the bit-vector.  Computer programs often make use of these operators,
which are non-linear when interpreted in the standard model of Peano arithmetic\footnote{
Although some of these operators can be seen as linear in a different algebraic structure,
e.g. \texttt{xor} corresponds to addition in the Galois field $\mathrm{GF}(2^k)$}.

\iffalse
\section{Combinatorics of Finite Termination}
In this section, we fix a model of computation, describe its semantics and
define the syntax of a language we will work over.

\subsection{Syntax and Semantics}

\begin{itemize}
 \item Our transition relation is $T(x, x') \subseteq X \times X$.
 \item Our loop condition is $L(x) \subseteq X$.
 \item Our ranking function is $R(x) : X \to Y$.
 \item Our state space has size $\| X \| = M = 2^k$.
 \item Our ranking co-domain has size $\| Y \| = N = 2^j$.
 \item The number of looping states is $\| L \| = l$.
 \item Our transition relation is deterministic and parititioned into chains of length $c_i$, with $l = \sum c_i$.
\end{itemize}

\subsection{Counting Programs}
\begin{itemize}
 \item There are a TON of programs (way more than you'd expect).
 \item There are a TON of terminating programs, and for our model of computation we can count
  how many (the Chaitin constant).
 \item There are a TON of ranking functions (way more than you'd expect, but not many as a
  fraction of programs).
 \item There are not many linear functions.
 \item Most terminating programs don't admit linear ranking functions.
 \item The Curry-Howard isomorphism
 \item Kolmogorov complexity is relevant for understanding termination proofs.
\end{itemize}


\begin{theorem}
 A random function $f : X \to Y$ is a ranking function for $(T, L)$ with probability

 $$N^{-l} \times \prod {{N-1} \choose c_i}$$
\end{theorem}

\begin{proof}
 Combinatorics.
\end{proof}


\begin{corollary}
 This number is really small (e.g. $10^{-193}$ for a 64-bit program with 1 variable and 10 looping states.
 Randomly sampling functions \& hoping they're ranking functions is not going to work.
\end{corollary}


\begin{conjecture}
 The probability that a random program $(T, L)$ is terminating (the Chaitin constant)
 is $0.7$.
\end{conjecture}

\begin{conjecture}
 The probability that a random program $(T, L)$ admits a linear ranking function is
 $0.1$.
\end{conjecture}

\begin{conjecture}
 The probability that a random, terminating program $(T, L)$ admits a linear ranking function
 is $0.2$.
\end{conjecture}


\begin{corollary}
 Most terminating programs do not have linear ranking functions.
\end{corollary}
\fi


\section{Termination as Second-Order Satisfaction} \label{sec:second.order}
%Program model? Programs: transition systems? Constraint generation? No CFG?

%% One difference from previous approaches is that our method is fully semantic. As a consequence, 
%% we do not care about the CFG (we do not need to encode the CFG 
%% through program counter in the second order constraints).


The problem of program verification can be reduced to the problem
of finding solutions to a second-order constraint \cite{DBLP:conf/pldi/GrebenshchikovLPR12,DBLP:conf/pldi/GulwaniSV08}. 
Our intention is to apply this approach to termination analysis. 
In this section we show how several variations of both the termination and the non-termination problem can be defined in second-order logic.  
%The second-order unknowns in this constraint are the unknown program invariants
%that are inductive and strong enough to prove the desired assertions. In this section we describe the conversion of programs to constraints

In fact, we identify a fragment of second-order logic with a constrained use of quantification that is expressive enough to encode both termination and non-termination.
We will suggestively refer to the fragment as the \emph{synthesis fragment}:

% The synthesis fragment is motivated by practical requirements in software verification.

\begin{definition}[Synthesis Fragment]
 A formula is in the synthesis fragment iff it is of the form
 \[
  \exists \vec{P},~ \vec{x} . ~\forall~ \vec{y} . \sigma(\vec{P}, \vec{x}, \vec{y})
 \]

where $\vec{P}$ ranges over sets, while $\vec{x}$ and $\vec{y}$ range over ground terms.
Function $\sigma: (X^n \times Y^m \to Z^k) \times X^n \times Y^m  \to \mathbb{B}$ can be viewed as a specification function
that  returns true iff the functions $\vec{P}$ compute appropriate outputs
when fed the inputs $\vec{x}$ and $\vec{y}$.  
\end{definition}

Checking satisfiability of a formula in the synthesis fragment corresponds to program synthesis and
%Solving the synthesis problem 
amounts to finding witnesses for the unknowns $\vec{P}$ and $\vec{x}$ that meet the specification
for all $\vec{y}$. 
If a pair $(\vec{P_0}, \vec{x})$ is a solution to the synthesis problem, then we write $(\vec{P_0}, \vec{x}) \models \sigma$.
For the remainder of the presentation, we drop the $\vec{x}$ and instead just write $x$, with the understanding
that all variables range over vectors.

In the remainder of this section, we show that the synthesis fragment 
is expressive enough to encode both termination and non-termination. %allow the formulation of both the termination and the non-termination problem. 
Following our formulation as second order satisfaction, %the framing of the halting problem as a program synthesis problem,
in Section~\ref{sec:synthesis} we present a solver for the synthesis fragment that models bit-accurate semantics. 

%% Following the framing of the halting problem as a program synthesis problem, 
%% we show how we solve this problem in Section~\ref{sec:synthesis}.

\subsection{An Isolated Loop}

We will begin our discussion by showing how to encode the (non-)termination of program consisting of a single loop 
in the synthesis fragment.  For the time being, a loop is a pair ${L= \langle G,T \rangle}$,
where the states $x$ satisfying the loop's guard are given by the predicate $G(x)$.
The body of the loop is encoded as the transition relation $T(x, x')$, meaning that
state $x'$ is reachable from state $x$ via a single iteration of the loop body.
For example, the loop in Figure~\ref{fig:motivation.a} is encoded as:
\begin{align*}
G(x) & = \{ x \mid x>0 \} \\
T(x,x') &= \{ \langle x, x' \rangle \mid x' = (x - 1) \, \& \, x \}
\end{align*}
We will abbreviate this with the notation:
\begin{align*}
G(x) & \triangleq x > 0 \\
T(x, x') & \triangleq x' = (x - 1) \, \& \, x
\end{align*}

\begin{figure*}
\begin{framed}
\begin{definition}[Second-order Unconditional Termination Formula {\bf [UT]}]
\label{def:UT}
\begin{align*}
 \exists R . \forall x, x' . & G(x) \wedge T(x, x') \rightarrow R(x) > 0 \wedge R(x) > R(x')
\end{align*}
\end{definition}

\begin{definition}[Non-Termination Formula - Open Recurrence Set  {\bf [ONT]}]
\label{def:ont}
 \begin{align*}
  \exists N, x_0 . \forall x . \exists x' . & N(x_0) ~ \wedge ~ N(x) \rightarrow G(x) ~ \wedge \\
							& N(x) \rightarrow T(x, x') \wedge N(x') 
 \end{align*}
\end{definition}

\begin{definition}[Non-Termination Formula - Closed Recurrence Set {\bf [CNT]}]
\label{def:cnt}
 \begin{align*}
  \exists N, x_0 . \forall x, x' . & N(x_0) ~ \wedge ~ N(x) \rightarrow G(x) ~ \wedge \\
							& N(x) \wedge T(x, x') \rightarrow N(x') 
 \end{align*}
\end{definition}

\end{framed}
\end{figure*}

\iffalse
Many loops do not terminate for all starting states, but are contained in programs that guarantee the loop will
terminate.  Traditional termination provers have difficulty reasoning about such conditionally-terminating loops.
We are able to handle such loops by computing \emph{termination invariants}.  This mechanism also allows us to
prove that programs with multiple loops terminate, even if the termination of some loop depends on the states
reachable after leaving a previous loop.

Our method for ranking function synthesis can be stated as follows:
discuss what spec is used (non-lexicographic vs lexicographic) + the completeness claims.
Any termination guarantees?  
\fi


\noindent {\bf Unconditional termination.}
To show that $L$ is unconditionally terminating (i.e. it eventually terminates regardless of the
state it starts in), we can find a ranking function for $L$.
The existence of a ranking function is equivalent to the satisfiability
of the formula from Definition~\ref{def:UT}, so a witness to the satisfiability
of formula {\bf [UT]} is also a ranking function and thus a proof of $L$'s unconditional termination.

Continuing the example of the program in Figure~\ref{fig:motivation.a}, we can see that
the corresponding synthesis formula {\bf [UT]} is satisfiable, as witnessed by the function $R(x) = x$.
So $R(x) = x$ constitutes a proof that the program in Figure~\ref{fig:motivation.a} is unconditionally
terminating.\\

\noindent{\bf Non-termination.}
Dually to termination, we might want to consider the non-termination of a program.  If a program terminates,
we can prove this by finding a ranking function %and supporting invariant 
witnessing the satisfiability of formula {\bf[UT]}.  What then would a proof of non-termination look like?

Gupta et al. \cite{DBLP:conf/popl/GuptaHMRX08} characterize non-termination of a transition relation $T$ by the existence of an \emph{(open) recurrence set},
i.e. a nonempty set of states $N$ such that for each $s \in N$ there
exists a transition to some $s'\in N$. 
For our case, given a loop $L = \langle G,T \rangle$, the notion of open recurrent set is encoded by formula {\bf [ONT]}. %Definition~\ref{def:nonterm-formula}.

If this formula is satisfiable, $N$ is an open recurrence set for $L$ which proves
$L$'s non-termination. The issue with this formula is the additional level of quantifier alternation as compared to the synthesis fragment
(it is an $\exists \forall \exists$ formula). %This means that we will not be able to use the solver for the synthesis fragment to solve it.

In order to formulate the non-termination problem inside the synthesis fragment, 
we make use of the notion of \emph{closed recurrence set} introduced by Chen et al. in \cite{DBLP:conf/tacas/ChenCFNO14}. 
As opposed to an open recurrence set, this is a $\exists \forall$ property: for each state in the recurrence set $N$, all of its successors 
must be in $N$. We note that if $T$ is deterministic, every open recurrence set is also a closed recurrence set (since each
state has at most one successor).  Thus, the non-termination problem for deterministic transition systems is equivalent to the
satisfiability of formula {\bf [CNT]}. %Definition~\ref{def:deterministic-nonterm-formula}.
%As our formulation is with respect to a given loop $L=\langle I,G,T \rangle$, we require the  
%recurrence set to include the loop's guard, $N(x) \rightarrow G(x)$. In other words, the loop's guard needs to be satisfied in order for the 
%infinite execution to happen.

Given that our program's state space is finite, a transition relation induces a infinite execution if and only if some state is 
visited infinitely often, or equivalently the state is visited twice in the course of the execution.
This gives us an alternative way of expression a non-termination proof: we can can try to find a witness $x$ to the satisfiability
of the formula
$$ \exists x . T^+(x, x)$$
However, deciding satisfiability of this formula directly requires a logic that includes a transitive closure operator, which
ours does not have.\\

\iffalse
\noindent {\bf Non-determinism.} A non-termination diagnosis procedure searching for a closed recurrence set under-approximates the transition relation, i.e. 
the closed recurrence set together with the under-approximation characterise non-termination \cite{DBLP:conf/tacas/ChenCFNO14}.
A potential difficulty with such a procedure lies in the handling of non-deterministic assignments. For illustration, consider the following loop:

\begin{lstlisting}[language=C]
while(x != 0) {
  y = nondet();
  x = x-y;
}
\end{lstlisting}

Only for certain values of $y$ the loop is non-terminating.
In order to restrict the values that may be assigned to $y$, we replace the non-deterministic choice with a fresh variable $a$ and use formula {\bf [CNT]}
to compute a closed recurrence set $N[a]$ parametrised by $a$. Now $N[a]$ becomes an assertion over $x \cup \{a\}$.
%, i.e. we under-approximate the transition relation. 
For this example, our technique computes $N[a](x,y,a) = ...$. \\%, where $a$ corresponds to the non-deterministic choice.  \\
%The issue with the closed recurrence set is that it yields an incomplete  for loops 
%that have non-deterministic assignments 
%parametric recurrence set

\fi

%% According to \cite{DBLP:conf/popl/GuptaHMRX08,DBLP:conf/tacas/ChenCFNO14}, a transition relation is non-terminating iff it has a recurrence set of states.
%% Candidate transition relations are 
%% \emph{lassos} in the program's CFG.
%% A lasso at a cutpoint location consists of two sequences
%% of transitions, the stem and the loop.
%% The stem is a finite path from an initial location to the cutpoint location. 
%% The loop is a finite path that starts and ends at the cutpoint
%% location by following a cyclic path through the CFG. 
%% A lasso induces an infinite execution if the infinite path obtained by traversing the stem and then unrolling
%% the loop infinitely many times is feasible. In this case, the lasso is said to be non-terminating.
%% We observe that in the case that $T$ is deterministic (that is, each state has
%% exactly one successor),  the non-termination problem is equivalent to the
%% satisfiability of Definition~\ref{def:deterministic-nonterm-formula}.

%% The method is incomplete as not all non-terminating
%% program executions are induced by lassos. An infinite behaviour
%% that is not periodic is illustrated by the following program:

%Our method is purely semantic. 

\subsection{Composing a Loop with its Environment}


\begin{figure*}
 \begin{framed}

\begin{definition}[Conditional Termination Formula {\bf [CT]}]
\label{def:ct}
 \begin{align*}
  \exists R, W . \forall x, x' . & I(x) \wedge G(x) \rightarrow W(x) ~ \wedge \\
                                 & G(x) \wedge W(x) \wedge T(x, x') \rightarrow W(x') \wedge R(x) > 0 
  \wedge R(x) > R(x')
 \end{align*}
\end{definition}

%%  \begin{definition}[Sequential Loops Termination Formula {\bf [ST]}]
%%   \begin{align*}
%% \label{def:multi-termination-formula}
%%   \exists R, Inv_1,..., Inv_n . \forall x_0,...,x_n, x_1',...,x_n'.  & P_0(x_0,x_1) \rightarrow Inv_1(x_1) ~  \\
%%  & \bigwedge_{i=1..n{-}1} (Inv_i(x_i) \wedge G_i(x_i) \wedge T_i(x_i, x_i') \rightarrow Inv_i(x_i')) ~  \\  
%%  & \bigwedge_{i=1..n{-}2} (Inv_i(x_i) \wedge \lnot G_i(x_i) \wedge P_{i+1}(x_i, x_{i+1}) \rightarrow Inv_{i+1}(x_{i+1})) ~ \wedge \\
%%  & Inv_{n-1}(x_{n-1}) \wedge \lnot G_{n-1}(x_{n-1}) \wedge P_n(x_{n-1},x_n) \wedge G_n(x_n) \rightarrow Inv_n(x_n) ~ \wedge \\
%%  & Inv_n(x_n) \wedge G_n(x_n) \wedge T(x_n, x_n') \rightarrow Inv_n(x_n') \wedge R(x_n) > 0 \wedge R(x_n) > R(x_n')
%%  \end{align*}
%% \end{definition}

%% \begin{definition}[Nested Loops Termination Formula {\bf [NT]}]
%% \label{def:nested-term-formula}
%%  \begin{align*}
%%   \exists R, S . \forall x, x' . & G_1(x) \wedge P_1(x,x') \rightarrow S(x',x') ~ \wedge \\
%%                                 & G_2(x') \wedge S(x,x') \wedge T(x',x'')\rightarrow S(x,x'') ~ \wedge \\
%% 				& G_1(x) \wedge P_1(x,x') \wedge \neg G_2(x') \wedge S(x',x'') \wedge 
%%                                 P_2(x'',x''') \wedge 
%%                                   R(x) > 0 \wedge R(x) > R(x''') 
%%  \end{align*} 
%% \end{definition}

%% \begin{definition}[Sequential Loops Non-Termination Formula {\bf [SNT]}]
%% \label{def:multi-termination-formula}
%%  \begin{align*}
%%   \exists R, Inv_1,..., Inv_n . \forall x_0,...,x_n, x_1',...,x_n'.  & P_0(x_0,x_1) \rightarrow Inv_1(x_1) ~  \\
%%  & \bigwedge_{i=1..n{-}1} (Inv_i(x_i) \wedge G_i(x_i) \wedge T_i(x_i, x_i') \rightarrow Inv_i(x_i')) ~  \\  
%%  & \bigwedge_{i=1..n{-}2} (Inv_i(x_i) \wedge \lnot G_i(x_i) \wedge P_{i+1}(x_i, x_{i+1}) \rightarrow Inv_{i+1}(x_{i+1})) ~ \wedge \\
%%  & Inv_{n-1}(x_{n-1}) \wedge \lnot G_{n-1}(x_{n-1}) \wedge P_n(x_{n-1},x_n) \wedge N(x_n)  ~ \wedge \\
%%                                                         & N(x_n) \rightarrow G_n(x_n) ~ \wedge 
%% 							 N(x_n) \wedge T_n(x_n, x_n') \rightarrow N(x_n') 
%%  \end{align*}
%% \end{definition}
 \end{framed}

\end{figure*}

Sometimes the termination behaviour of a loop depends on its environment.  That is to say,
the loop may not terminate if started in some particular state, but the rest of the program
ensures that such a state cannot be reached on entry to the loop.  The program as a whole
terminates, but if the loop were considered in isolation we would not be able to prove that
it terminates.  We must therefore encode a loop's interaction with the rest of
the program in order to do a sound termination analysis.\\

\iffalse
Let us assume that we have done some preprocessing of our program which has identified
loops, straight line code blocks and the control flow between these.  In particular,
the control flow analysis has determined which order these code blocks execute in,
and the nesting structure of the loops.
\fi

\noindent {\bf Conditional termination.}
If $L$'s termination depends on the state it begins
executing in, we say that $L$ is \emph{conditionally terminating}.
The information we require of the environment is a predicate $I$ which
overapproximates the set of states that $L$ may begin executing in.
That is to say, for each state $x$ that is reachable on entry to $L$,
we have $I(x)$.

Conditional termination is then equivalent to the
formula {\bf [CT]} of Defintion~\ref{def:ct}. If this formula is satisfiable,
two witnesses are returned:
\begin{itemize}
\item $W$ is an inductive invariant of $L$ that is established by the initial states $I$ if the loop
guard $G$ is met.
\item $R$ is a ranking function for $L$ as restricted by $W$ -- that is to say, $R$ need only
be well founded on those states satisfying $W \wedge G$.  Since $W$ is an inductive invariant of $L$,
$R$ is strong enough to show that $L$ terminates from any of its initial states.
\end{itemize}

$W$ is called a \emph{supporting invariant} for $L$ and $R$ proves termination relative to $W$.
We require that $I \wedge G$ is strong enough to establish the base case of $W$'s inductiveness.

Conditional termination is illustrated by the program in Figure~\ref{fig:motivation.h},
which is encoded as:
\begin{align*}
            I(\langle x, y \rangle) & \triangleq y = 1 \\
            G(\langle x, y \rangle) & \triangleq x > 0 \\
            T(\langle x, y \rangle, \langle x', y' \rangle) & \triangleq x' = x - y \wedge y' = y 
\end{align*}
If the initial states $I$ are ignored this loop cannot be shown to terminate, since any state with $y = 0$ and $x > 0$
would lead to a non-terminating execution.

However, formula {\bf [CT]} is satisfiable, as witnessed by the ranking function
$R(\langle x,y\rangle) = x$ and supporting invariant $W(\langle x, y \rangle ) \triangleq y = 1$.
This constitutes a proof that the program as a whole terminates, since the loop always begins
executing in a state that guarantees its termination.\\

\noindent {\bf Nested loops.}
If $L$'s body contains another loop $L'$, we cannot directly apply either formula {\bf [UT]} or
{\bf [CT]} or prove that $L$ terminates.  This is because we don't have direct access to the
single step transition relation for $L$'s body.  Instead, we consider $L'$ to be part of
$L$'s environment, which we model with a relation $S$.  We require that $S$ overapproximates
$L'$ in the sense that it satisfies the following formula:
\begin{align*}
 \forall x, x'. G(x) \wedge W(x) \wedge T'^*(x, x') \wedge \lnot G'(x') \rightarrow S(x, x')
\end{align*}
Where $G$ and $G'$ are respectively $L$ and $L'$'s guards, and $T'^*$ is the reflexive transitive closure of
the inner loop ($L'$)'s transition relation.

To give an example, if we wish to prove that the outer loop in Figure~\ref{fig:nested} terminates,
it suffices to summarise the inner loop with the relation:
\begin{align*}
S(\langle x, y, z \rangle, \langle x', y', z' \rangle) & \triangleq x' = x \wedge y = 1
\end{align*}
Then the ranking function $R(x, y, z) = x$ proves termination of the outer loop $L(G, S)$.\\


\begin{figure}
\begin{lstlisting}
while (x > 0) {
  z = x, y = z + 1;
  while (z > 0) {
    z--, y--;
  }
  x -= y;
}
\end{lstlisting}
\caption{A nested loop\label{fig:nested}}
\end{figure}

\noindent {\bf Composing the environment with a loop.}
While proving that loop $L$ terminates, we create constraints on the environment in the
form of the predicate $I$ and the summary relation $S$.  For each loop $L'$ nested in the body
of $L$, we must add some more constraints saying that $S$ overapproximates $L'$.
Similarly, for each loop $L''$ appearing before $L$ in the program's control flow, we
must add constraints saying that $I$ overapproximates the states reachable via $L''$.
The details of how to create these constraints are standard, so
rather than presenting the algorithm for generating the constraints, we direct the
reader's attention to Figure~\ref{fig:environment-model}.  This figure contains a non-trivial program
along with the constraint system
encoding the termination of the outer loop.  Since the program contains sequential composition
of loops and nested loops, the constraint
system involves termination invariants $W_1, W_2, W_3$ and the inner loop summary $S$.
Note that despite its intricacy, the constraint system is still a formula in the synthesis fragment.
Since the outer loop of this program does indeed terminate, the system is satisfiable, as witnessed by:
\begin{align*}
W_1(\langle v, x, y, z \rangle ) & \triangleq x \leq y + 1 \\
W_2(\langle v, x, y, z \rangle ) & \triangleq x = y + 1 \\
S(\langle v, x, y, z \rangle, \langle v', x', y', z' \rangle) & \triangleq x ' = x \wedge y' = y \wedge z' + v' = x' \wedge v' \leq y' \\
R(x) & = x
\end{align*}


\begin{figure*}
\begin{framed}
\begin{minipage}{0.19\textwidth}
\begin{lstlisting}
x = 0;
while (x <= y)
  x++;

while (x > 0) {
  z = x;
  v = 0;

  while (v < y) {
    z--;
    v++;
  }

  x -= z;
  y -= z;
}
\end{lstlisting}
\end{minipage}
\vline
\begin{minipage}{0.82\textwidth}
\begin{align*}
 \exists W_1, W_2, R, S . \forall v, x, y, z, v', x', y', z' . \\
   x = 1 & \rightarrow W_1(v, x, y, z) \, \wedge \\
   x \leq y \wedge W_1(v, x, y, z) & \rightarrow W_1(v, x+1, x, y, z) \, \wedge \\
   x > 0 \wedge x > y \wedge W_1(v, x, y, z) & \rightarrow W_2(v, x+1, y, z) \, \wedge \\
   %x > 0 \wedge W_2(v, x, y, z) & \rightarrow W_3(0, x, y, x) \, \wedge \\
   %v < y \wedge W_3(v, x, y, z) & \rightarrow W_3(v+1, x, y, z-1) \, \wedge \\
   %v \geq y \wedge W_3(v, x, y, z) & \rightarrow W_2(v, x-z, y-z, z) \, \wedge \\
   S(\langle v, x, y, z, \rangle, \langle v', x', y', z' \rangle) \wedge v < y & \rightarrow S(\langle v, x, y, z \rangle, \langle v+1, x, y, z-1 \rangle) \, \wedge \\
   x > 0 \wedge W_2(v, x, y, z) & \rightarrow S(\langle v, x, y, z \rangle, \langle 0, x, y, x \rangle) \, \wedge \\
   x > 0 \wedge W_2(v, x, y, z) \wedge S(\langle v, x, y, z \rangle, \langle v', x', y', z' \rangle) \wedge v' \geq y' & \rightarrow \\
   & W_2(v', x' - z', y' - z', z') \, \wedge \\
   & R(v, x, y, z) > 0 \, \wedge \\
   & R(v, x, y, z) > R(v', x' - z', y'-z', z')
\end{align*}
\end{minipage}
\caption{A non-trivial program and its constraint system\label{fig:environment-model}}
\end{framed}
\end{figure*}

\iffalse

\noindent {\bf Sequential loops.}
Conditional termination allows us to
prove that programs with multiple loops terminate, even if the termination of some loop depends on the states
reachable after leaving a previous loop.
%The conditional termination formula becomes more complex in the presence of multiple loops.
For illustration, consider the following program with $n$ sequential loops $\forall i=1..n. ~L_i=(x_i,G_i,T_i)$ and
the assertions $\forall i=1..n. ~P_i$ modelling the program statements in between loops. 

\begin{lstlisting}[mathescape=true]
$P_1$
while ($G_1$) { $T_1$ }
$P_2$
while ($G_2$) { $T_2$ }
...
$P_n$
while ($G_n$) { $T_n$ }
\end{lstlisting}

In order to prove that the $n^{th}$ loop terminates, we need to apply the {\bf [CT]} formula for $L_n$.
The challenge is determining the initial states  $I(x_n)$ at the loop's entry point.  
The termination problem for $L_n$ is thus equivalent to the satisfiability of
Definition~\ref{def:multi-termination-formula}.  If this formula is satisfiable:
\begin{itemize}
\item $Inv_i$ is an inductive invariant of $L_i$ for $i=1..{n-1}$ as established by the conjuncts:
$$\bigwedge_{i=1..n{-}1} (Inv_i(x_i) \wedge G_i(x_i) \wedge T_i(x_i, x_i') \rightarrow Inv_i(x_i')) $$

\item Each loop invariant $Inv_i$ with $i=1..{n-2}$ is strong enough to establish $Inv_{i+1}$:
$$\bigwedge_{i=1..n{-}2} (Inv_i(x_i) \wedge \lnot G_i(x_i) \wedge P_{i+1}(x_i, x_{i+1}) {\rightarrow} Inv_{i+1}(x_{i+1})) ~$$

\item When $L_n$'s guard holds, $Inv_{n-1}$ 
is strong enough to establish $Inv_n$, i.e. $Inv_n$ holds for the program states after $L_n$'s entry point:
$$ Inv_{n-1}(x_{n-1}) \wedge \lnot G_{n-1}(x_{n-1}) \wedge P_n(x_{n-1},x_n) \wedge G_n(x_n) $$
$$\qquad\qquad\rightarrow Inv_n(x_n)$$

\item $Inv_n$ is a supporting termination invariant of $L_n$ and $R$ is a ranking function relative to $Inv_n$:
$$Inv_n(x_n) \wedge G_n(x_n) \wedge T(x_n, x_n') \rightarrow Inv_n(x_n')$$
$$ \qquad \qquad \wedge R(x_n) > 0 \wedge R(x_n) > R(x_n')$$
\end{itemize}

\todo{add example?}\\

\noindent{\bf Nested loops.}
For brevity reasons, we illustrate our approach to handling nested loops for only two loops, but the approach can be easily generalised to any number of nested loops:
\begin{lstlisting}[mathescape=true]
while ($G_1$) { 
  $P_1$ 
  while ($G_2$) { $T$ }
  $P_2$
}
\end{lstlisting}

The termination of the outer loop is equivalent to the formula in Definition~\ref{def:nested-term-formula}.
The formula requires an auxiliary assertion $S(x,x')$ representing a binary relation between the initial states at the inner loop's entry point
and their successors according to the transition relation $T$. If this formula is satisfiable, then $R$ is a ranking function of the outer loop.

In order to find a termination argument for the inner loop, we use {\bf [CT]} where the initial states are given by 
$\neg G_1(x) \wedge P_1(x,x') \rightarrow I(x')$.


\noindent{\bf Sequential loops.}
Discuss {\bf [SNT]}.\\

\noindent{\bf Nested loops.}
\fi

\subsection{Generalised synthesis formula.}
Our design: for each loop always search for lexicographic ranking function + supporting invariant OR recurrence set.

Note: given a program with multiple loops (sequential and nested), we could potentially compute termination/non-termination 
arguments for all of them in the same formula. Currently, our tool generates a separate formula for each loop.

%% \subsection{Program Synthesis as Second-Order Satisfaction}

%% With the exception of Definition~\ref{def:nonterm-formula}, each of the second-order formulae above
%% belongs to the synthesis fragment.  We use this name because the program synthesis problem can be
%% described as finding a satisfying assigment to the following formula, which is the general case of
%% the synthesis fragment:

%% \begin{definition}[Synthesis Formula]
%%  \label{def:synth-formula}
%%  $$\exists P, x . \forall y . \sigma(P, x, y)$$
%% \end{definition}


\section{Satisfiability of a Formula in the Synthesis Fragment} \label{sec:synthesis}
%
\iffalse
\subsection{The Search Space and the Kolmogorov Complexity of a Ranking Function}
\begin{conjecture}
The lexicographic ordering does not influence the size of the search space. Thus, finding potentially lexicographic termination arguments is not more difficult than finding non-lexicographic ones.   
\end{conjecture}

As a consequence of the aforementioned conjecture, we do not need to commit to a specific form of the termination argument. While other approaches, e.g. \cite{DBLP:conf/tacas/LeikeH14}, 
conduct independent searches for each possible form of the ranking function with some of them futile whenever the assumed constrained ranking function does not exist, we have a single search that aims at finding the ranking function with the lowest Kolmogorov complexity. 
\fi
%
%
\input{kalashnikov}

\subsection{Genetic Programming and Incremental Evolution} \label{sec:gp}
To generate candidate (non-)termination proofs in the synthesise phase of the refinement loop,
we make use of genetic programming (GP) \cite{langdon:fogp} as an alternative to model checking and exhaustive search.  
Genetic programming provides an intelligent and adaptive way of searching through the space of computer programs
for an individual that is highly fit in solving the problem at hand
by using the Darwinian principle of survival and reproduction of the fittest.
Thus, the program that emerges from the genetic programming paradigm is a consequence of fitness. 

In our setting, we start with a population of random programs of size ..
We then genetically breed the population of these programs by applying the genetic operators 
{\sc crossover} and {\sc mutate}. The crossover operator takes two programs
and combines their code in some what to create a new program.  The mutate operator takes a single
program and randomly changes parts of its code, again creating a new program. 
Both these operators are applied to programs selected from the population in 
proportion to their observed fitness, i.e. a program is fit if it satisfies the (non-)termination specification.
Thus, our fitness function counts the number of test cases on which a program met the given specification.
Essentially, we plan a trajectory through the space of computer programs that will lead to programs with improved fitness.
%by considering those that meet the (non-)termination specification on more inputs until.

\todo{Talk about the fitness landscape?}

\begin{definition}
 A \emph{fitness landscape} is the space of all programs along with their fitness.
\end{definition}

A potential issue might be that, in our setting, a fitness landscape isn't really very smooth, e.g. small changes in program representation
don't correspond to small changes in fitness. However, genetic programming's efficiency was shown to be unrelated to the smoothness 
of the fitness landscape \cite{langdon:fogp}.

\todo{mention incremental GP?}

%% The general idea is to start with a population
%% of random programs and evolve a good one.  ``Good'' in this case means that the program
%% satisfies our specification.  To do this evolution, we compute a fitness for each program
%% and repeatedly apply genetic operators to the population based on this fitness.  The operators
%% used are {\sc crossover} and {\sc mutate}.  The crossover operator takes two programs
%% and combines their code in some what to create a new program.  The mutate operator takes a single
%% program and randomly changes parts of its code, again creating a new program.  We arrange
%% things so that the fitter a program is, the more likely it is to be selected as a parent
%% that will be crossover'd to produce a child in the next generation.  Our fitness function
%% is just the number of test cases on which the program met the specification.

\iffalse
We begin by observing that the asymptotic complexity of all of our synthesis
backends are equal, assuming $P \neq NP$.  This complexity is:

$$O\left(2^{K(f)}\right)$$

Where $K(f)$ is the Kolmogorov complexity of $f$, which is $O(\log Y^X) = O(X)$
so the complexity is doubly exponential in the width of $X$.


\begin{theorem}
 Fitness landscapes form a lattice.  Adding test vectors corresponds to abstraction refinement on this
 lattice, which is why incremental GP works well.
\end{theorem}

\begin{proof}
 Trivial.
\end{proof}


\begin{conjecture}
 A single fitness landscape isn't really very smooth (e.g. small changes in program representation
 don't correspond to small changes in fitness), so GP probably shouldn't work very well.

 But it does.
\end{conjecture}
\fi


\section{Soundness, Completeness and Complexity}
\begin{theorem}
 \label{thm:synth-sound}
 Algorithm~\ref{alg:abstract-refinement-code} is sound -- if it terminates with witness $P$ then
 $P \models \sigma$.
\end{theorem}

\begin{proof}
 The procedure {\sc RefinementLoop} terminates only if {\sc Verif} returns ``valid''.  In that
 case, $\exists x . \lnot \sigma(x, P)$ is unsatisfiable and so $\forall x . \sigma(x, P)$ holds.
\end{proof}

\begin{theorem}
 \label{thm:synth-semicomplete}
 If the existential first-order theory used to express the specification $\sigma$ is decidable,
 algorithm~\ref{alg:abstract-refinement-code} is semi-complete -- if a program $P \models \sigma$
 exists then algorithm~\ref{alg:abstract-refinement-code} will terminate.  However if no program
 satisfies the specification, the algorithm may not terminate.  Furthermore if the domain of inputs $X$
 is finite, the algorithm is guaranteed to terminate.
\end{theorem}

\begin{proof}
 Since the {\sc ExplicitSearch} routine enumerates all programs (as can be seen by induction on
 the program length $l$), it will eventually enumerate a program that meets the specification
 in whatever set of inputs are currently being tracked.  Since the first order theory is
 decidable, the query in {\sc Verif} will succeed for this program, causing the algorithm to terminate.
 The set of correct programs is therefore recursively enumerable and algorithm~\ref{alg:abstract-refinement-code}
 enumerates this set, so it is semi-complete.

 If the domain $X$ is finite then the loop in procedure {\sc RefinementLoop} can only
 iterate $\| X \|$ times, since by this time all of the elements of $X$ would have been
 added to the inputs set.  Therefore if the {\sc Synth} procedure always terminates (which it does
 by assumption of decidability), the whole algorithm terminates.
\end{proof}


\begin{theorem}
\label{thm:sound}
 {\sc Headshot} is sound -- if it returns a verdict of termination, the program under
 analysis terminates on all inputs.  Similarly if it returns a verdict of non-termination,
 the program under analysis has at least one infinite execution.
\end{theorem}

\begin{proof}
 {\sc Headshot}'s output constitutes a constructive, machine checked proof of (non-)termination.
\end{proof}

\begin{theorem}
\label{thm:complete-termination}
 {\sc Headshot} is complete for terminating programs -- if a program terminates, {\sc Headshot} will find a proof that it does.
\end{theorem}

\begin{proof}
 If the program under analysis $P$ has variables $v_1, \ldots, v_k$ each of which is $b$ bits wide, its state space $\mathcal{S}$ is of size $2^{bk}$.
 A ranking function $R: \mathcal{S} \to \mathcal{D}$ for $P$ exists iff $P$ terminates.  Since $R$ is injective, we have that
 $\| \mathcal{D} \| \geq \| \mathcal{S} \|$.  If $\| \mathcal{D} \| > \| \mathcal{S} \|$, we can construct a function $R': \mathcal{S} \to \mathcal{D'}$
 with $ \| \mathcal{D'} = \| \mathcal{S} \|$ by just setting $R' = R|_\mathcal{S}$, i.e. $R'$ is just the restriction of $R$ to $\mathcal{S}$
 Since $\mathcal{S}$ already comes equipped with a natural well ordering we can also construct $R'' = \iota \circ R'$
 where $\iota: \mathcal{D'} \to \mathcal{S}$ is the unique order isomorphism from $\mathcal{D'}$ to $\mathcal{S}$.
 So assuming that $P$ terminates, there is some ranking function $R''$ that is just a permutation of $\mathcal{S}$.
 If the number of variables $k > 1$ then in general the ranking function will be lexicographic with dimension $\leq k$
 and each co-ordinate of the output being a single $b$-bit value.

 It is fairly easy to see that any finite permutation is computed by a finite program in the proof language generated
 by {\sc Kalashnikov}.  A very inefficient construction which computes the permutation $R(x) = x+1$ for one variable
 is:
 \begin{verbatim}
t1 = 0
t2 = v1 == 0
t3 = ITE(t2, 1, t1)
t4 = v1 == 1
t5 = ITE(t4, 2, t3)
...
 \end{verbatim}
It is easy to see how this generalises to computing an arbitrary permutation.

So we can see that every permutation is computed a program of size at most $b \times 2^{bk + 1}$.  Since
{\sc Kalashnikov} enumerates all programs in order of length, it will eventually check
a program computing each permutation of $\mathcal{S}$ and so will eventually check a program
computing the ranking function $R''$.  Checking that a single program satisfies the specification
is a decidable problem, and the search as a whole terminates.
\end{proof}

\begin{theorem}
 {\sc Headshot} is complete for deterministic programs -- {\sc Headshot} will terminate when run on
 any program with a deterministic transition relation.
\end{theorem}

\begin{proof}
 If the program under analysis is terminating, then by Theorem~\ref{thm:complete-termination} {\sc Headshot}
 will terminate having computed a ranking function.

 Conversely if the program is non-terminating, {\sc Headshot} will terminate
 having computed a recurrence set.  Since, by assumption, the program under analysis is determinstic,
 Definition~\ref{def:ont} is equivalent to Definition~\ref{def:cnt}.
 That is to say, each open recurrence set is also a closed recurrence set.  Since the specification for a predicate
 to encode a closed recurrence set is in the synthesis fragment, {\sc Kalashnikov} will find a program computing
 such a predicate if one exists.  The proof is similar to the proof of Theorem~\ref{thm:complete-termination}.
\end{proof}


Since termination for bitvector programs is known to be PSPACE-complete~\cite{DBLP:conf/tacas/CookKRW10} it
is perhaps unsurprising that we are able to decide it.  We will now show that our time complexity is
asymptotically a function of the Kolmogorov complexity of the (non-)termination proof, and argue heuristically
that this gives our procedure various desirable qualities.

\begin{theorem}
 {\sc Kalashnikov} has time complexity $NP^{NP}(K(\sigma))$
\end{theorem}

\begin{theorem}
 {\sc Headshot} uses a single call to {\sc Kalashnikov} and uses an encoding with $O(1)$
 overhead.  It therefore has time complexity $NP^{NP}(K(\tau(P))$ where $\tau(P)$ is the
 termination specification for program $P$.
\end{theorem}


In Section~\ref{sec:synthesis} we will describe a procedure for solving the synthesis formula.
This procedure has the property that it will find the shortest program meeting the
specification, and as a consequence the runtime of the program synthesiser is dominated
by the size of this shortest program.  To frame the discussion of the runtime of our
termination proving procedure, we first recall the definition of the Kolmogorov complexity
of a function $f$:

\begin{definition}[Kolmogorov complexity]
 The Kolmogorov complexity $K(f)$ is the length of the shortest program that
 computes $f$.
\end{definition}

We can extend this definition slightly to talk about the Kolmogorov complexity of a
synthesis problem in terms of its specification:

\begin{definition}[Kolmogorov complexity of a synthesis problem]
 The Kolmogorov complexity of a program specification $K(\sigma)$ is the length of the shortest
 program $P$ such that $P \models \sigma$.
\end{definition}

We will later show that the time complexity of our synthesis procedure is $NP^{NP}(K(\sigma))$,
which means that for even moderately large $K(\sigma)$ our procedure is intractably slow.  Conversely
if $K(\sigma)$ is small we will be able to find a termination proof, regardless of other parameters
such as the size of the program under analysis.  To put this another way, under the assumption
that $K(\sigma)$ is small for a program's termination problem, we will find a ranking function
quite rapidly.  We will now investigate the properties of functions with low Kolmogorov complexity,
and show that the assumption of a low-Kolmogorov ranking function is much weaker than the assumption
of a linear ranking function.


\begin{theorem}
 Linear functions have low Kolmogorov complexity.
\end{theorem}

\begin{proof}
 The function $f: X \to Y$ can be computed with a program consisting of
 $2 \cdot \dim(X) \cdot \dim(Y) - \dim(Y)$ instructions (1 multiplication and 1 addition for
 each cell in the matrix representing $f$).  Therefore,
 $K(f) \leq 2 \cdot \dim(X) \cdot \dim(Y) - \dim(Y)$.
\end{proof}

\begin{theorem}
Assuming a reasonable program encoding, the probability that a random program of length $l$ computes
a linear function is $O(2^{-l})$.
\end{theorem}

\begin{proof}
 (Do this proof properly).
 
 Otherwise, we'd need to have an exponential number of programs computing the same function.
 That would be an unreasonable program encoding.
\end{proof}


Therefore the number of non-linear functions $f$ with $K(f) \leq \kappa$
grows exponentially with $\kappa$, while the number of linear functions
grows only linearly.  This shows that assuming the existence of a linear
ranking function is much stronger than assuming the existence of a short
termination proof.  In addition to being a much weaker assumption,
we argue that low Kolmogorov complexity is a more natural assumption than
linearity.  Humans tend to write programs they can understand.  It's hard
to quantify exactly what ``understandable'' means, but we think that
``having a short proof'' is closer to the mark than ``having a linear proof''.

\todo{do something with this?}
Since each loop is bounded by a constant, and each recursive function call is
limited to a constant depth, a \newC program necessarily terminates and in
fact does so in $O(1)$ time.  If we call the largest loop bound~$k$, then
a Bounded Model Checker with an unrolling bound of $k$ will be a complete
decision procedure for the safety of the program.  For a \newC program of
size $l$ and with largest loop bound~$k$, a Bounded Model Checker will
create a SAT problem of size $O(lk)$.  Conversely, a SAT problem
of size $s$ can be converted trivially into a loop-free \newC program
of size $O(s)$.  The safety problem for \newC is therefore NP-complete,
which means it can be decided fairly efficiently for many practical
instances.


\iffalse
\begin{corollary}
 LKC is a weaker assumption than linearity.
\end{corollary}


\begin{theorem}
 LKC programs do not always have LKC ranking functions.
\end{theorem}

\begin{proof}
 This would solve the halting problem, Goldbach conjecture, Collatz conjecture.
\end{proof}

\begin{conjecture}
 High-Kolmogorov-complexity (HKC) programs often have LKC ranking functions.
\end{conjecture}

\begin{theorem}
 \textsc{Headshot} is biased towards finding ranking functions with
 low-Kolmogorov-complexity (LKC).
\end{theorem}

\begin{proof}
 Trivial.
\end{proof}

\subsection{The linearity assumption vs. the LKC one for ranking functions}

\begin{conjecture}
 Most LKC programs compute non-linear functions, but linear functions are LKC.
 So LKC is a weaker assumption than linearity.
\end{conjecture}

\begin{corollary}
 \textsc{Headshot} can often prove termination where linear methods cannot.
\end{corollary}
\fi


\section{Experiments}
We implemented our method by backing onto the {\sc Kalashnikov} program synthesiser.
We ran the tool on 40 benchmarks taken from the termination category of SVCOMP'15.
The experiments were performed on a 4-core 3.3GHz i5-2500k with 8GB of RAM.


\iffalse
We proved termination for a bunch of programs, see Fig.~\ref{fig:linear} and Fig.~\ref{fig:nonlinear}.

\begin{figure*}
\centering
\begin{tabular}{|l|r|r||r|r|r|r|}
\hline
    & LOC & \shortstack{Rank function \\ size} & \textsc{T2} & \textsc{ARMC} & \textsc{Headshot} & \textsc{Headshot-Linear} \\
    \hline
    \hline
 P1 & 10 & 3 & 100s & 70s & 0.1s & \bf{0.01s} \\
 P2 & 10 & 3 & 100s & 70s & 0.1s & \bf{0.01s} \\
 P3 & 10 & 3 & 100s & 70s & 0.1s & \bf{0.01s} \\
 \hline
\end{tabular}
\caption{Termination for linear programs with disjunctive, linear ranking functions\label{fig:linear}}
\end{figure*}
\fi

\begin{figure*}
\centering
\footnotesize
\begin{tabular}{|l|r|c|c|c|c|c|r|r|c|r|r|}
\hline
    & LOC & Terminates? & \shortstack{Linear \\ program?} & \shortstack{Linear ranking \\ function?}  & Conditional? & Float? & Dimension & \shortstack{Ranking \\ program size} & Res & Time (s) & Iterations\\
    \hline
    \hline
\input{table}
    \hline
\end{tabular}

\caption{\textsc{Headshot} termination for nonlinear programs with nonlinear ranking functions\label{fig:nonlinear}}
 \end{figure*}

 \section{Conclusions and Related Work}
%\subsection{Termination analysis}
Automated program termination is a research topic that has received a fair amount of attention from the software verification community.
In order to compare our technique to the rest of the area, 
Figure~\ref{fig:handletable} summarises the related works with respect to the restrictions they impose on the transition relations as well as the form of the computed ranking functions. 


Somehow expected, most of the techniques are specialised in the synthesis of linear ranking functions for linear programs over integers (or rationals) \cite{DBLP:conf/pldi/CookPR06,DBLP:conf/cav/LeeWY12,DBLP:conf/popl/Ben-AmramG13,DBLP:conf/vmcai/P04,DBLP:conf/atva/HeizmannHLP13,DBLP:conf/cav/BradleyMS05,DBLP:conf/tacas/CookSZ13}. 
Among them, 
Lee et al. make use of transition predicate abstraction, algorithmic learning, and decision procedures to compute transition
invariants as proofs for the termination of linear programs \cite{DBLP:conf/cav/LeeWY12}.
Leike and Heizmann present a new method for the constraint-based synthesis
of termination arguments for linear loop programs based on
linear ranking templates \cite{DBLP:conf/tacas/LeikeH14}.
Linear ranking functions supported by inductive linear invariants for loops with linear guards and transitions: \cite{DBLP:conf/cav/BradleyMS05}. 
Learning: \cite{DBLP:journals/corr/HeizmannHP14}


%A program is lasso-shaped if it is composed by a stem followed by a single loop without branching, i.e. there is only one path. 
%Consequently, the termination argument can be very simple. There are numerous techniques specialised in
%proving termination of lasso-shaped programs efficiently \cite{DBLP:conf/popl/Ben-AmramG13,DBLP:conf/cav/BradleyMS05,DBLP:conf/atva/HeizmannHLP13,DBLP:conf/vmcai/P04}. 

While the synthesis of termination arguments for linear programs over integers is indeed well-covered in the literature, 
there is very limited work for programs over machine integers.
Cook et al. present a method based on a reduction to Presburger
arithmetic, and a template-matching approach for predefined classes of
ranking functions based on reduction to SAT- and QBF-solving \cite{DBLP:conf/tacas/CookKRW10}.
Similarly, the only work we are aware of that can compute non-linear ranking functions  
for imperative loops with polynomial guards and polynomial assignments
is \cite{DBLP:conf/vmcai/BradleyMS05}. However, this work extends only to polynomials.

Given the lack of research in handling \emph{not-linear programs}, as well as \emph{programs over bit-vectors and floats},  
our work focuses on covering these areas. 
One of the obvious conclusions that can be reached from observing Figure~\ref{fig:handletable}, 
is that most of the works tend to specialise on a certain aspect of termination proving that they can solve efficiently. 
Conversely to this view, we aim for \emph{generality}, as we do not restrict the form of the synthesised ranking functions, nor the form of the input programs.


As mentioned in Section~\ref{sec:intro}, approaches based on Ramsey's theorem compute a set of local termination conditions that decrease as execution follows through the loop
and require expensive reachability analyses
\cite{DBLP:conf/lpe/CodishG03,DBLP:conf/lics/PodelskiR04,DBLP:conf/pldi/CookPR06}.
In an attempt to reduce the complexity of checking the validity of the termination argument, 
Cook et al present an iterative termination proving procedure that searches for 
lexicographic termination arguments \cite{DBLP:conf/tacas/CookSZ13}, 
whereas Kroening et al. strengthen the termination argument such that it becomes a transitive relation \cite{DBLP:conf/cav/KroeningSTW10}.

Proving program termination implies the simultaneous search for a termination argument and a supporting invariant.
For this purpose, several tools alternate 
between calls to a safety prover and calls to a ranking function synthesis tool \cite{}. 
In order to share more information about the state of the termination proofs between the two tools, 
Brockschmidt et al. use a single representation of the state of the termination proof search that both tools operate over, 
resulting in performance improvements \cite{DBLP:conf/cav/BrockschmidtCF13}.
In \cite{DBLP:conf/cav/BradleyMS05}, Bradley et al. combine the generation of ranking functions with the generation of invariants to
form one constraint solving problem such that the necessary supporting invariants for the ranking function are discovered on demand.
In our setting, both the ranking function and the supporting invariant are iteratively constructed through the same refinement loop.

 
%In our setting, a candidate termination argument is iteratively constructed. 
%A candidate termination argument is composed out of a ranking function 
%and a supporting invariant. 

%% The safety prover proves or disproves the
%% validity of the current argument via the search for invariants. Refinement of the
%% current termination argument is performed using the output of a rank function
%% synthesis tool when applied to counterexamples found by the safety prover.

%The existing work on termination is primarily divided into structural (syntactic) vs. semantic approaches.  
%For example, terminationg of term rewriting systems is largely structural, whereas DWF analysis (cf. Terminator) is more semantic. While it deals
%with transition relations, it also uses some amount of syntax in that it identifies loops \& looping paths.



%-- Usually the termination argument for the program LOOPS
%on Figure 1 is based on a lexicographic combination
%of well-founded orderings.

While program termination has been extensively studied, much less research has been conducted in the area of proving nontermination.
% A counterexample to termination is an infinite program execution. 
Gupta et al. dynamically enumerate lasso-shaped candidate
paths for counterexamples, and then statically prove their feasibility \cite{DBLP:conf/popl/GuptaHMRX08}. 
In \cite{DBLP:conf/tacas/ChenCFNO14}, Chen et al. prove nontermination via
reduction to safety proving. Their iterative algorithm uses counterexamples to a fixed safety property
to refine an underapproximation of a program. 

% program analysis as constraint solving:
%% how the constraint-based approach can be used to model a wide spectrum of program analyses in an 
%%expressive domain containing disjunctions and conjunctions of linear inequalities.
 

\bibliographystyle{abbrvnat}
\bibliography{synth}{}

\end{document}
